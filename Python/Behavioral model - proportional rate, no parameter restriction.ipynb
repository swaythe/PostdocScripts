{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is the basic proportional rate diffusion model from Palmer, Huk and Shadlen '05. \n",
    "# The overall fits are good for subject accuracies but mRT fits are not very good. \n",
    "# More specifically, the lowering of mRTs observed at low distance and high coherence \n",
    "# is not captured by the model.\n",
    "\n",
    "# I am not imposing any constraints on the parameters (+ve or -ve) except to say that x is positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## These are the pre-modelling steps where behavioral data is extracted from files.\n",
    "\n",
    "# Load required libraries\n",
    "% matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from math import factorial as fact\n",
    "\n",
    "# List subjects to fit\n",
    "subs = ['Sub01', 'Sub02', 'Sub04', 'Sub05', 'Sub06', 'Sub08', 'Sub10', 'Sub11', 'Sub13']\n",
    "nSub = len(subs)\n",
    "\n",
    "# Initialize arrays to hold PC, mean and SD of RT, and # trials \n",
    "# for each coherence-distanct combination\n",
    "# These values are obtained from the .csv files\n",
    "pCs = np.zeros((20, nSub))\n",
    "mRTs = np.zeros((20, nSub))\n",
    "sdRTs = np.zeros((20, nSub))\n",
    "Ns = np.zeros((20, nSub))\n",
    "\n",
    "# Initialise a variable to hold # correct trials\n",
    "# This will be computed from Ns and pCs\n",
    "Rs = np.zeros((20, nSub))\n",
    "\n",
    "# Extract behavioral data (PC, mean and SD of RT, # trials) from csv files\n",
    "for si in range(nSub):\n",
    "    csvFile = '../Data/Behavior/' + subs[si] + '_behavData.csv'\n",
    "    behavData = pd.read_csv(csvFile, header=None)\n",
    "    \n",
    "    # Split the file in PC, mean RT and SD RT\n",
    "    # Flatten each subject's values for ease of programming\n",
    "    pCs[:,si] = np.array(behavData[0:4]).flatten()\n",
    "    mRTs[:,si] = np.array(behavData[4:8]).flatten()\n",
    "    sdRTs[:,si] = np.array(behavData[8:12]).flatten()\n",
    "    Ns[:,si] = np.array(behavData[12:]).flatten()\n",
    "    Rs[:,si] = np.round(Ns[:,si] * pCs[:,si])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Model definition\n",
    "\n",
    "# Parameters to fit:\n",
    "# A: Boundary\n",
    "# x: Stimulus strength\n",
    "# k: Proportionality constant (Stim. str. = kx)\n",
    "# tR: Residual time\n",
    "\n",
    "# Equations to fit for each stimulus strength:\n",
    "# pC = 1 / (1+exp(-2*A*k*abs(x)))\n",
    "# mRT = A / (k*x) * tanh(A*k*x) + tR\n",
    "\n",
    "# We can get approximate values for A, k and tR from Palmer et. al. '05\n",
    "# Ranges of parameters to start with:\n",
    "# A: 0.5 - 1\n",
    "# k: 5 - 40\n",
    "# tR: 0.25 - 0.5 (in seconds)\n",
    "# x: 0 - 1\n",
    "\n",
    "# To identify best fit, calculate the likelihood of predicted pC and mRT and find the maximum likelihood.\n",
    "\n",
    "# Likelihood of pC follows a binomial distribution\n",
    "# Lp = n! / (r!(n-r)! * pC(x)^r * (1-pC(x))^(n-r), where\n",
    "# n = # trials, r = # required correct\n",
    "\n",
    "# Likelihood of mRT follows a Gaussian distribution\n",
    "# Lrt = 1 / (SDrt * (sqrt(2*pi))) * e^-((mRT(x) - oRT(x)) / SDrt)^2 * 1/2, where\n",
    "# oRT = observed mRT, mRT = predicted mRT, SDrt = SD of predicted mRT\n",
    "\n",
    "# VARrt = VARtd + VARtr, where\n",
    "# VARtd = variance in decision time, VARtr = variance in residual time. Thus,\n",
    "# VARrt = (A * tanh(A*k*x) - A*k*x * sech(A*k*x)) / (k*x)^3 + (0.1 * tR)^2\n",
    "\n",
    "# Final fit measure is the log likelihood, which is the sum of the likelihoods of accuracy and mean RT, \n",
    "# over all combinations of coherence and distance\n",
    "# Lprt = sigma(x)(ln(Lp(s)) + ln(Lrt(x)))\n",
    "\n",
    "# The first pass of the model will be to estimate values of x without any assumptions about stimulus relationtips.\n",
    "# The stopping point will be the point of least error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## First run of the model. \n",
    "\n",
    "# Initialize A, k and tR parameters\n",
    "A, dA = np.linspace(-5, 5, 10, retstep=True)\n",
    "# k, dk = np.linspace(0.3, 2, 20, retstep=True)\n",
    "k, dk = np.linspace(-5, 5, 10, retstep=True)\n",
    "tR, dtR = np.linspace(-5, 5, 10, retstep=True)\n",
    "\n",
    "As, ks, tRs = np.meshgrid(A, k, tR)\n",
    "As = As.flatten()\n",
    "ks = ks.flatten()\n",
    "tRs = tRs.flatten()\n",
    "\n",
    "# This is the overall number of permutations of A, k and tR being performed\n",
    "nPar = len(As)\n",
    "\n",
    "# Initialize stimulus strength parameter\n",
    "# x, dx = np.linspace(0.1, 10, 200, retstep=True)\n",
    "x, dx = np.linspace(0.01, 5, 200, retstep=True)\n",
    "\n",
    "# Initialize arrays that hold predicted accuracies and RTs\n",
    "epc = np.ones((nPar, len(x), 20, nSub)) * -9\n",
    "ert = np.ones((nPar, len(x), 20, nSub)) * -9\n",
    "sdrt = np.ones((nPar, len(x), 20, nSub)) * -9\n",
    "\n",
    "## Initialize the array that holds the\n",
    "# individual likelihood values\n",
    "lpc = np.zeros((nPar, len(x), 20, nSub))\n",
    "lrt = np.zeros((nPar, len(x), 20, nSub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# From the set of parameters, calculate the (expected) predicted PC and RT\n",
    "# and then find the likelihood that these estimates match the observed PC and RT\n",
    "for si in range(nSub):\n",
    "    for pi in xrange(nPar):\n",
    "        for cdi in range(20):\n",
    "            # Calculate expected accuracy for each coherence-distance combination\n",
    "            epc[pi,:,cdi,si] = 1 / (1 + np.exp(-2 * As[pi] * ks[pi] * abs(x)))\n",
    "            # And the likelihood of this accuracy\n",
    "            lpc[pi,:,cdi,si] = fact(Ns[cdi,si]) / (fact(Rs[cdi,si]) * fact(Ns[cdi,si]-Rs[cdi,si])) * \\\n",
    "                                (epc[pi,:,cdi,si] ** Rs[cdi,si]) * \\\n",
    "                                ((1 - epc[pi,:,cdi,si]) ** (Ns[cdi,si] - Rs[cdi,si]))\n",
    "            \n",
    "            # Calculate expected mean RT for each coherence-distance combination\n",
    "            ert[pi,:,cdi,si] = As[pi] / (ks[pi] * x) * np.tanh(As[pi] * ks[pi] * x) + tRs[pi] \n",
    "            # And standard error of the mean\n",
    "            sdrt[pi,:,cdi,si] = np.sqrt(((As[pi] * np.tanh(As[pi] * ks[pi] * x) - \\\n",
    "                    As[pi] * ks[pi] * x * (1/np.cosh(np.square(As[pi] * ks[pi] * x)))) / \\\n",
    "                    (ks[pi] * x) ** 3 + np.square(0.1 * tRs[pi])) / Ns[cdi,si])\n",
    "            # And the likelihood of observing that RT\n",
    "            lrt[pi,:,cdi,si] = 1 / (sdrt[pi,:,cdi,si] * np.sqrt(2 * np.pi)) * \\\n",
    "                                np.e ** (-1/2 * np.square((ert[pi,:,cdi,si] - mRTs[cdi,si]) / sdrt[pi,:,cdi,si]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# See if there are any weird PC, mRT or sdrt values generated in the parameter space\n",
    "print(np.sum(np.isinf(epc)))\n",
    "print(np.sum(np.isnan(epc)))\n",
    "print(np.sum(epc < 0))\n",
    "print(np.sum(np.isinf(ert)))\n",
    "print(np.sum(np.isnan(ert)))\n",
    "print(np.sum(ert < 0))\n",
    "print(np.sum(np.isinf(sdrt)))\n",
    "print(np.sum(np.isnan(sdrt)))\n",
    "print(np.sum(sdrt < 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This figure takes a long time to plot because there is a lot of data to \n",
    "# flatten and then plot. The gist is that: \n",
    "# - lpc ranges from 0 to 1 for all sujbects\n",
    "# - lrt ranges from 0 to 60 for all subjects\n",
    "\n",
    "plt.figure()\n",
    "for si in range(nSub):\n",
    "    plt.subplot(3,3,si+1)\n",
    "    plt.plot(lpc[...,si].flatten(), '.')\n",
    "    \n",
    "plt.figure()\n",
    "for si in range(nSub):\n",
    "    plt.subplot(3,3,si+1)\n",
    "    plt.plot(lrt[...,si].flatten(), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find indices where sdrt is NaN (or, variance is negative)\n",
    "tmpId = np.where(np.isnan(sdrt))[0]\n",
    "sdIdx = np.unravel_index(tmpId, sdrt.shape)\n",
    "\n",
    "# Find the fraction of trials that have NaN sdrt - 0.0134\n",
    "print(len(sdIdx[0])/np.double(np.prod(sdrt.shape)))\n",
    "\n",
    "# First see if it's any specific subjects that show this effect - no\n",
    "print(np.unique(sdIdx[3]))\n",
    "for i in range(nSub):\n",
    "    print(np.sum(sdIdx[3] == i))\n",
    "\n",
    "# Any specific CD combinations - no\n",
    "print(np.unique(sdIdx[2]))\n",
    "for i in range(20):\n",
    "    print(np.sum(sdIdx[2] == i))\n",
    "\n",
    "# Any specific x's - smaller ones\n",
    "print(np.unique(sdIdx[1]))\n",
    "for i in range(len(x)):\n",
    "    print(np.sum(sdIdx[1] == i))\n",
    "\n",
    "# Any specific A-k-tR combinations - first one\n",
    "print(np.unique(sdIdx[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First find the best values of x for each CD combination.\n",
    "# Once that is done, calculate the likelihood of each A-k-tR combination\n",
    "# at the best x values.\n",
    "\n",
    "# NOTE: After careful consideration, I have determined that normalizing the \n",
    "# likelihood values does not give a better fit.\n",
    "\n",
    "bestXcd = np.ones((nPar, 20, nSub), dtype = np.int) * -9\n",
    "totLL = np.zeros((nPar, nSub))\n",
    "\n",
    "for si in range(nSub):\n",
    "    for pi in range(nPar):\n",
    "        # At each A-k-tR combination, find the index of x value \n",
    "        # that maximizes likelihood for each CD combination\n",
    "        bestXcd[pi,:,si] = np.argmax(lpc[pi,:,:,si] * lrt[pi,:,:,si], 0)\n",
    "        \n",
    "        for cdi in range(20):\n",
    "            # Sum over all CDs to obtain overall likelihood for the \n",
    "            # give A-k-tR combination\n",
    "            totLLpc[pi,si] += lpc[pi,bestXcd[pi,cdi,si],cdi,si]\n",
    "            totLLrt[pi,si] += lrt[pi,bestXcd[pi,cdi,si],cdi,si]\n",
    "            totLL[pi,si] += np.log(lpc[pi,bestXcd[pi,cdi,si],cdi,si]) + \\\n",
    "                            np.log(lrt[pi,bestXcd[pi,cdi,si],cdi,si])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find the parameters for which likelihood is maximum\n",
    "# There are some NaN values in the likelihood matrix so exclude those\n",
    "maxParId = np.zeros(nSub, dtype=np.int)\n",
    "\n",
    "# Record the values of best fit x for each CD combination\n",
    "bestx = np.zeros((20, nSub), dtype = np.int)\n",
    "\n",
    "for si in range(nSub):\n",
    "    maxParId[si] = np.where(totLL[:,si] == np.nanmax(totLL[:,si]))[0]\n",
    "    bestx[:,si] = bestXcd[maxParId[si],:,si]\n",
    "    # print(np.where(maxLLx[:,si] == np.nanmax(maxLLx[:,si]))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for si in range(nSub):\n",
    "    print(maxParId[si], round(totLL[maxParId[si],si],ndigits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subXs = np.zeros((20, nSub))\n",
    "# Print the parameter values predicting maximum likelihoods\n",
    "# for the different coherence-distance combinations\n",
    "for si in range(nSub):\n",
    "    print(round(As[maxParId[si]],ndigits=3), round(ks[maxParId[si]],ndigits=3), round(tRs[maxParId[si]],ndigits=3))\n",
    "    print(np.reshape(x[bestx[:,si]].round(decimals=2),(4,5)))\n",
    "    #subXs[:,si] = x[bestx[:,si]].round(decimals=2)\n",
    "    \n",
    "#np.savetxt('SubXs_all.csv', subXs, fmt = '%.2f', delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the observed (behavior) and expected (model) PC and RT\n",
    "for si in range(nSub):\n",
    "    temp = []\n",
    "    ymin = min(pCs[:,si])\n",
    "    ymax = max(pCs[:,si])\n",
    "    for cdi in range(20):\n",
    "        temp.append(epc[maxParId[si], bestx[cdi,si], cdi, si])\n",
    "    if min(temp) < ymin:\n",
    "        ymin = min(temp)\n",
    "    if max(temp) > ymax:\n",
    "        ymax = max(temp)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.subplot(221)\n",
    "    plt.title(subs[si] + ' Behavior')\n",
    "    plt.plot(np.reshape(pCs[:,si],(4,5)),'o-')\n",
    "    plt.ylim((ymin, ymax))\n",
    "    \n",
    "    plt.subplot(222)\n",
    "    plt.title('Model1')\n",
    "    plt.plot(np.reshape(temp,(4,5)),'o-')\n",
    "    plt.ylim((ymin,ymax))\n",
    "    \n",
    "    temp = []\n",
    "    ymin = min(mRTs[:,si])\n",
    "    ymax = max(mRTs[:,si])\n",
    "    for cdi in range(20):\n",
    "        temp.append(ert[maxParId[si], bestx[cdi,si], cdi, si])\n",
    "    if min(temp) < ymin:\n",
    "        ymin = min(temp)\n",
    "    if max(temp) > ymax:\n",
    "        ymax = max(temp)\n",
    "    \n",
    "    plt.subplot(223)\n",
    "    plt.plot(np.reshape(mRTs[:,si],(4,5)),'o-')\n",
    "    plt.ylim((ymin,ymax))\n",
    "    plt.xlabel('Coherence')\n",
    "    \n",
    "    plt.subplot(224)\n",
    "    plt.plot(np.reshape(temp,(4,5)),'o-')\n",
    "    plt.ylim((ymin,ymax))\n",
    "    plt.xlabel('Coherence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "minA = np.zeros(nSub)\n",
    "maxA = np.zeros(nSub)\n",
    "mink = np.zeros(nSub)\n",
    "maxk = np.zeros(nSub)\n",
    "mintR = np.zeros(nSub)\n",
    "maxtR = np.zeros(nSub)\n",
    "\n",
    "nd = 3 # Number of deltas before and after best fit value\n",
    "\n",
    "for si in range(nSub):\n",
    "    # Set up A, k and tR parameters for the next round of simulations\n",
    "    # Use the bestx values from the first run, don't fit for x again\n",
    "    \n",
    "    # First set the range of all variables. \n",
    "    # minVar = bestValue - dVar*nd : bestValue + dVar*nd\n",
    "    # If the new minimum is <= 0, then set it to the old minimum.\n",
    "    minA[si] = As[maxParId[si]] - nd * dA\n",
    "    maxA[si] = As[maxParId[si]] + nd * dA\n",
    "    # if minA[si] < 0:\n",
    "    #    minA[si] = A[0]\n",
    "    \n",
    "    mink[si] = ks[maxParId[si]] - nd * dk\n",
    "    maxk[si] = ks[maxParId[si]] + nd * dk\n",
    "    # if mink[si] < 0:\n",
    "    #    mink[si] = k[0]\n",
    "        \n",
    "    mintR[si] = tRs[maxParId[si]] - nd * dtR\n",
    "    maxtR[si] = tRs[maxParId[si]] + nd * dtR\n",
    "    # if mintR[si] < 0:\n",
    "    #    mintR[si] = tR[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(minA.round(decimals=3))\n",
    "print(maxA.round(decimals=3))\n",
    "print(mink.round(decimals=3))\n",
    "print(maxk.round(decimals=3))\n",
    "print(mintR.round(decimals=3))\n",
    "print(maxtR.round(decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nStep = 9 # Number of values tested, per parameter\n",
    "\n",
    "A = np.zeros((nStep, nSub))\n",
    "dA = np.zeros(nSub)\n",
    "k = np.zeros((nStep, nSub))\n",
    "dk = np.zeros(nSub)\n",
    "tR = np.zeros((nStep, nSub))\n",
    "dtR = np.zeros(nSub)\n",
    "\n",
    "# This is the overall number of permutations of A, k and tR being performed\n",
    "nPar = nStep ** 3\n",
    "\n",
    "As = np.zeros((nPar, nSub))\n",
    "ks = np.zeros((nPar, nSub))\n",
    "tRs = np.zeros((nPar, nSub))\n",
    "\n",
    "for si in range(nSub):\n",
    "    A[:,si], dA[si] = np.linspace(minA[si], maxA[si], nStep, retstep=True)\n",
    "    k[:,si], dk[si] = np.linspace(mink[si], maxk[si], nStep, retstep=True)\n",
    "    tR[:,si], dtR[si] = np.linspace(mintR[si], maxtR[si], nStep, retstep=True)\n",
    "\n",
    "    tempAs, tempks, temptRs = np.meshgrid(A[:,si], k[:,si], tR[:,si])\n",
    "    As[:,si] = tempAs.flatten()\n",
    "    ks[:,si] = tempks.flatten()\n",
    "    tRs[:,si] = temptRs.flatten()\n",
    "    \n",
    "    # Initialize arrays that hold predicted accuracies and RTs\n",
    "    epc = np.ones((nPar, 20, 9)) * -9\n",
    "    ert = np.ones((nPar, 20, 9)) * -9\n",
    "    sdrt = np.ones((nPar, 20, 9)) * -9\n",
    "\n",
    "    ## Initialize the array that holds the\n",
    "    # individual likelihood values\n",
    "    lpc = np.zeros((nPar, 20, 9))\n",
    "    lrt = np.zeros((nPar, 20, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# From the set of parameters, calculate the (expected) predicted PC and RT\n",
    "# and then find the likelihood that these estimates match the observed PC and RT\n",
    "for si in range(nSub):\n",
    "    for pi in xrange(nPar):\n",
    "        for cdi in range(20):\n",
    "            # Calculate expected accuracy for each coherence-distance combination\n",
    "            epc[pi,cdi,si] = 1 / (1 + np.exp(-2 * As[pi,si] * ks[pi,si] * abs(x[bestx[cdi,si]])))\n",
    "\n",
    "            # Calculate likelihood of accuracy for this CD combination\n",
    "            lpc[pi,cdi,si] = fact(Ns[cdi,si]) / (fact(Rs[cdi,si]) * fact(Ns[cdi,si]-Rs[cdi,si])) * \\\n",
    "                                (epc[pi,cdi,si] ** Rs[cdi,si]) * \\\n",
    "                                ((1 - epc[pi,cdi,si]) ** (Ns[cdi,si] - Rs[cdi,si]))\n",
    "            \n",
    "            # Calculate expected mean RT for each coherence-distance combination\n",
    "            ert[pi,cdi,si] = As[pi,si] / (ks[pi,si] * x[bestx[cdi,si]]) * \\\n",
    "                                np.tanh(As[pi,si] * ks[pi,si] * x[bestx[cdi,si]]) + tRs[pi,si] \n",
    "            # Calculate SD of mean RT \n",
    "            sdrt[pi,cdi,si] = np.sqrt(((As[pi,si] * np.tanh(As[pi,si] * ks[pi,si] * x[bestx[cdi,si]]) - \\\n",
    "                    As[pi,si] * ks[pi,si] * x[bestx[cdi,si]] * \\\n",
    "                    (1/np.cosh(np.square(As[pi,si] * ks[pi,si] * x[bestx[cdi,si]])))) / \\\n",
    "                    (ks[pi,si] * x[bestx[cdi,si]]) ** 3 + np.square(0.1 * tRs[pi,si])) / Ns[cdi,si])\n",
    "            # Calculate likelihood of mean RT for this CD combination\n",
    "            lrt[pi,cdi,si] = 1 / (sdrt[pi,cdi,si] * np.sqrt(2 * np.pi)) * \\\n",
    "                                np.e ** (-1/2 * np.square((ert[pi,cdi,si] - mRTs[cdi,si]) / sdrt[pi,cdi,si]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#maxLLcd = np.ones((nPar, 20, nSub)) * -9\n",
    "totLL = np.zeros((nPar, nSub))\n",
    "\n",
    "for si in range(nSub):\n",
    "    for pi in range(nPar):\n",
    "        # maxLLcd[pi,:,si] = np.argmax(lpc[pi,:,:,si]+lrt[pi,:,:,si],0)\n",
    "        for cdi in range(20):\n",
    "            #totLL[pi,si] += np.log(lpc[pi,cdi,si]) + \\\n",
    "            #                    np.log(lrt[pi,cdi,si])\n",
    "            totLL[pi,si] += np.log(lpc[pi,cdi,si]) + \\\n",
    "                            np.log(lrt[pi,cdi,si])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for si in range(nSub):\n",
    "    plt.subplot(3,3,si+1)\n",
    "    plt.plot(totLL[:,si],'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find the parameters for which likelihood is maximum\n",
    "# There are some NaN values in the likelihood matrix so exclude those\n",
    "maxParId = np.zeros(nSub)\n",
    "\n",
    "for si in range(nSub):\n",
    "    maxParId[si] = np.where(totLL[:,si] == np.nanmax(totLL[:,si]))[0]\n",
    "    # print(np.where(maxLLx[:,si] == np.nanmax(maxLLx[:,si]))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for si in range(nSub):\n",
    "    print(totLL[maxParId[si],si])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the parameter values predicting maximum likelihoods\n",
    "# for the different coherence-distance combinations\n",
    "for si in range(nSub):\n",
    "    print(round(As[maxParId[si],si],ndigits=3), round(ks[maxParId[si],si],ndigits=3), \\\n",
    "          round(tRs[maxParId[si],si],ndigits=3))\n",
    "    # print(np.reshape(maxLLcd[maxParId[si],:,si],(4,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the observed (behavior) and expected (model) PC and RT\n",
    "for si in range(nSub):\n",
    "    temp = []\n",
    "    ymin = min(pCs[:,si])\n",
    "    ymax = max(pCs[:,si])\n",
    "    for cdi in range(20):\n",
    "        temp.append(epc[maxParId[si],cdi,si])\n",
    "    if min(temp) < ymin:\n",
    "        ymin = min(temp)\n",
    "    if max(temp) > ymax:\n",
    "        ymax = max(temp)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.subplot(221)\n",
    "    plt.title(subs[si] + ' Behavior')\n",
    "    plt.plot(np.reshape(pCs[:,si],(4,5)),'o-')\n",
    "    plt.ylim((ymin, ymax))\n",
    "    \n",
    "    plt.subplot(222)\n",
    "    plt.title('Model')\n",
    "    plt.plot(np.reshape(temp,(4,5)),'o-')\n",
    "    plt.ylim((ymin,ymax))\n",
    "\n",
    "    temp = []\n",
    "    ymin = min(mRTs[:,si])\n",
    "    ymax = max(mRTs[:,si])\n",
    "    for cdi in range(20):\n",
    "        temp.append(ert[maxParId[si],cdi,si])\n",
    "    if min(temp) < ymin:\n",
    "        ymin = min(temp)\n",
    "    if max(temp) > ymax:\n",
    "        ymax = max(temp)\n",
    "    \n",
    "    plt.subplot(223)\n",
    "    plt.plot(np.reshape(mRTs[:,si],(4,5)),'o-')\n",
    "    plt.ylim((ymin,ymax))\n",
    "    plt.xlabel('Coherence')\n",
    "    \n",
    "    plt.subplot(224)\n",
    "    plt.plot(np.reshape(temp,(4,5)),'o-')\n",
    "    plt.ylim((ymin,ymax))\n",
    "    plt.xlabel('Coherence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "minA = np.zeros(nSub)\n",
    "maxA = np.zeros(nSub)\n",
    "mink = np.zeros(nSub)\n",
    "maxk = np.zeros(nSub)\n",
    "mintR = np.zeros(nSub)\n",
    "maxtR = np.zeros(nSub)\n",
    "\n",
    "for si in range(nSub):\n",
    "    # Set up A, k and tR parameters for the next round of simulations\n",
    "    # Use the bestx values from the first run, don't fit for x again\n",
    "    \n",
    "    # First set the range of all variables. \n",
    "    # minVar = bestValue - dVar*nd : bestValue + dVar*nd\n",
    "    # If the new minimum is <= 0, then set it to the old minimum.\n",
    "    minA[si] = As[maxParId[si],si] - nd * dA[si]\n",
    "    maxA[si] = As[maxParId[si],si] + nd * dA[si]\n",
    "    # if minA[si] < 0:\n",
    "    #    minA[si] = A[0,si]\n",
    "    \n",
    "    mink[si] = ks[maxParId[si],si] - nd * dk[si]\n",
    "    maxk[si] = ks[maxParId[si],si] + nd * dk[si]\n",
    "    # if mink[si] < 0:\n",
    "    #    mink[si] = k[0,si]\n",
    "        \n",
    "    mintR[si] = tRs[maxParId[si],si] - nd * dtR[si]\n",
    "    maxtR[si] = tRs[maxParId[si],si] + nd * dtR[si]\n",
    "    # if mintR[si] < 0:\n",
    "    #    mintR[si] = tR[0,si]\n",
    "\n",
    "print(minA.round(decimals=3))\n",
    "print(maxA.round(decimals=3))\n",
    "print(mink.round(decimals=3))\n",
    "print(maxk.round(decimals=3))\n",
    "print(mintR.round(decimals=3))\n",
    "print(maxtR.round(decimals=3))\n",
    "\n",
    "A = np.zeros((nStep, nSub))\n",
    "dA = np.zeros(nSub)\n",
    "k = np.zeros((nStep, nSub))\n",
    "dk = np.zeros(nSub)\n",
    "tR = np.zeros((nStep, nSub))\n",
    "dtR = np.zeros(nSub)\n",
    "\n",
    "As = np.zeros((nPar, nSub))\n",
    "ks = np.zeros((nPar, nSub))\n",
    "tRs = np.zeros((nPar, nSub))\n",
    "\n",
    "for si in range(nSub):\n",
    "    A[:,si], dA[si] = np.linspace(minA[si], maxA[si], nStep, retstep=True)\n",
    "    k[:,si], dk[si] = np.linspace(mink[si], maxk[si], nStep, retstep=True)\n",
    "    tR[:,si], dtR[si] = np.linspace(mintR[si], maxtR[si], nStep, retstep=True)\n",
    "\n",
    "    tempAs, tempks, temptRs = np.meshgrid(A[:,si], k[:,si], tR[:,si])\n",
    "    As[:,si] = tempAs.flatten()\n",
    "    ks[:,si] = tempks.flatten()\n",
    "    tRs[:,si] = temptRs.flatten()\n",
    "\n",
    "    # Initialize arrays that hold predicted accuracies and RTs\n",
    "    epc = np.ones((nPar, 20, 9)) * -9\n",
    "    ert = np.ones((nPar, 20, 9)) * -9\n",
    "    sdrt = np.ones((nPar, 20, 9)) * -9\n",
    "\n",
    "    ## Initialize the array that holds the\n",
    "    # individual likelihood values\n",
    "    lpc = np.zeros((nPar, 20, 9))\n",
    "    lrt = np.zeros((nPar, 20, 9))\n",
    "    \n",
    "# From the set of parameters, calculate the (expected) predicted PC and RT\n",
    "# and then find the likelihood that these estimates match the observed PC and RT\n",
    "for si in range(nSub):\n",
    "    for pi in xrange(nPar):\n",
    "        for cdi in range(20):\n",
    "            # Calculate expected accuracy for each coherence-distance combination\n",
    "            epc[pi,cdi,si] = 1 / (1 + np.exp(-2 * As[pi,si] * ks[pi,si] * abs(x[bestx[cdi,si]])))\n",
    "\n",
    "            # Calculate likelihood of accuracy for this CD combination\n",
    "            lpc[pi,cdi,si] = fact(Ns[cdi,si]) / (fact(Rs[cdi,si]) * fact(Ns[cdi,si]-Rs[cdi,si])) * \\\n",
    "                                (epc[pi,cdi,si] ** Rs[cdi,si]) * \\\n",
    "                                ((1 - epc[pi,cdi,si]) ** (Ns[cdi,si] - Rs[cdi,si]))\n",
    "            \n",
    "            # Calculate expected mean RT for each coherence-distance combination\n",
    "            ert[pi,cdi,si] = As[pi,si] / (ks[pi,si] * x[bestx[cdi,si]]) * \\\n",
    "                                np.tanh(As[pi,si] * ks[pi,si] * x[bestx[cdi,si]]) + tRs[pi,si] \n",
    "            # Calculate SD of mean RT \n",
    "            sdrt[pi,cdi,si] = np.sqrt(((As[pi,si] * np.tanh(As[pi,si] * ks[pi,si] * x[bestx[cdi,si]]) - \\\n",
    "                    As[pi,si] * ks[pi,si] * x[bestx[cdi,si]] * \\\n",
    "                    (1/np.cosh(np.square(As[pi,si] * ks[pi,si] * x[bestx[cdi,si]])))) / \\\n",
    "                    (ks[pi,si] * x[bestx[cdi,si]]) ** 3 + np.square(0.1 * tRs[pi,si])) / Ns[cdi,si])\n",
    "            # Calculate likelihood of mean RT for this CD combination\n",
    "            lrt[pi,cdi,si] = 1 / (sdrt[pi,cdi,si] * np.sqrt(2 * np.pi)) * \\\n",
    "                                np.e ** (-1/2 * np.square((ert[pi,cdi,si] - mRTs[cdi,si]) / sdrt[pi,cdi,si]))\n",
    "                \n",
    "#maxLLcd = np.ones((nPar, 20, nSub)) * -9\n",
    "totLL = np.zeros((nPar, nSub))\n",
    "\n",
    "for si in range(nSub):\n",
    "    for pi in range(nPar):\n",
    "        # maxLLcd[pi,:,si] = np.argmax(lpc[pi,:,:,si]+lrt[pi,:,:,si],0)\n",
    "        for cdi in range(20):\n",
    "            totLL[pi,si] += np.log(lpc[pi,cdi,si]) + \\\n",
    "                                np.log(lrt[pi,cdi,si])\n",
    "                \n",
    "for si in range(nSub):\n",
    "    plt.subplot(3,3,si+1)\n",
    "    plt.plot(totLL[:,si],'.')\n",
    "    \n",
    "# Find the parameters for which likelihood is maximum\n",
    "# There are some NaN values in the likelihood matrix so exclude those\n",
    "maxParId = np.zeros(nSub)\n",
    "\n",
    "for si in range(nSub):\n",
    "    maxParId[si] = np.where(totLL[:,si] == np.nanmax(totLL[:,si]))[0]\n",
    "    # print(np.where(maxLLx[:,si] == np.nanmax(maxLLx[:,si]))[0])\n",
    "    \n",
    "for si in range(nSub):\n",
    "    print(totLL[maxParId[si],si])\n",
    "    \n",
    "# Print the parameter values predicting maximum likelihoods\n",
    "# for the different coherence-distance combinations\n",
    "for si in range(nSub):\n",
    "    print(round(As[maxParId[si],si],ndigits=3), round(ks[maxParId[si],si],ndigits=3), \\\n",
    "          round(tRs[maxParId[si],si],ndigits=3))\n",
    "    # print(np.reshape(maxLLcd[maxParId[si],:,si],(4,5)))\n",
    "    \n",
    "# Plot the observed (behavior) and expected (model) PC and RT\n",
    "for si in range(nSub):\n",
    "    temp = []\n",
    "    ymin = min(pCs[:,si])\n",
    "    ymax = max(pCs[:,si])\n",
    "    for cdi in range(20):\n",
    "        temp.append(epc[maxParId[si],cdi,si])\n",
    "    if min(temp) < ymin:\n",
    "        ymin = min(temp)\n",
    "    if max(temp) > ymax:\n",
    "        ymax = max(temp)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.subplot(221)\n",
    "    plt.title(subs[si] + ' Behavior')\n",
    "    plt.plot(np.reshape(pCs[:,si],(4,5)),'o-')\n",
    "    plt.ylim((ymin, ymax))\n",
    "    \n",
    "    plt.subplot(222)\n",
    "    plt.title('Model')\n",
    "    plt.plot(np.reshape(temp,(4,5)),'o-')\n",
    "    plt.ylim((ymin,ymax))\n",
    "\n",
    "    temp = []\n",
    "    ymin = min(mRTs[:,si])\n",
    "    ymax = max(mRTs[:,si])\n",
    "    for cdi in range(20):\n",
    "        temp.append(ert[maxParId[si],cdi,si])\n",
    "    if min(temp) < ymin:\n",
    "        ymin = min(temp)\n",
    "    if max(temp) > ymax:\n",
    "        ymax = max(temp)\n",
    "    \n",
    "    plt.subplot(223)\n",
    "    plt.plot(np.reshape(mRTs[:,si],(4,5)),'o-')\n",
    "    plt.ylim((ymin,ymax))\n",
    "    plt.xlabel('Coherence')\n",
    "    \n",
    "    plt.subplot(224)\n",
    "    plt.plot(np.reshape(temp,(4,5)),'o-')\n",
    "    plt.ylim((ymin,ymax))\n",
    "    plt.xlabel('Coherence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
