{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is the basic proportional rate diffusion model from Palmer, Huk and Shadlen '05. \n",
    "# The overall fits are good for subject accuracies but mRT fits are not very good. \n",
    "# More specifically, the lowering of mRTs observed at low distance and high coherence \n",
    "# is not captured by the model.\n",
    "\n",
    "# I am imposing the constraint that all parameters be positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## These are the pre-modelling steps where behavioral data is extracted from files.\n",
    "\n",
    "# Load all required libraries\n",
    "% matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from math import factorial as fact\n",
    "# List subjects to fit\n",
    "subs = ['Sub01', 'Sub02', 'Sub04', 'Sub05', 'Sub06', 'Sub08', 'Sub10', 'Sub11', 'Sub13']\n",
    "nSub = len(subs)\n",
    "\n",
    "# Define number of coherences per distance\n",
    "nC = 4\n",
    "# Define number of distances per coherence\n",
    "nD = 4\n",
    "\n",
    "# Initialize arrays to hold PC, mean and SD of RT, and # trials \n",
    "# for each coherence-distanct combination\n",
    "# These values are obtained from the .csv files\n",
    "pCs = np.zeros((nC*nD, nSub))\n",
    "mRTs = np.zeros((nC*nD, nSub))\n",
    "sdRTs = np.zeros((nC*nD, nSub))\n",
    "Ns = np.zeros((nC*nD, nSub))\n",
    "\n",
    "# Initialise a variable to hold # correct trials\n",
    "# This will be computed from Ns and pCs\n",
    "Rs = np.zeros((nC*nD, nSub))\n",
    "\n",
    "# Extract behavioral data (PC, mean and SD of RT, # trials) from csv files\n",
    "for si in range(nSub):\n",
    "    csvFile = '../Data/Behavior/' + subs[si] + '_behavData.csv'\n",
    "    behavData = pd.read_csv(csvFile, header=None)\n",
    "    \n",
    "    # Split the file in PC, mean RT and SD RT\n",
    "    # Flatten each subject's values for ease of programming\n",
    "    temp = np.array(behavData[0:4])\n",
    "    pCs[:,si] = temp[:,1:].flatten()\n",
    "    temp = np.array(behavData[4:8])\n",
    "    mRTs[:,si] = temp[:,1:].flatten()\n",
    "    temp = np.array(behavData[8:12])\n",
    "    sdRTs[:,si] = temp[:,1:].flatten()\n",
    "    temp = np.array(behavData[12:])\n",
    "    Ns[:,si] = temp[:,1:].flatten()\n",
    "    Rs[:,si] = np.round(Ns[:,si] * pCs[:,si])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pCs[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters to fit:\n",
    "# A: Boundary\n",
    "# x: Stimulus strength\n",
    "# k: Proportionality constant (Stim. str. = kx)\n",
    "# tR: Residual time\n",
    "\n",
    "# Equations to fit for each stimulus strength:\n",
    "# pC = 1 / (1+exp(-2*A*k*abs(x)))\n",
    "# mRT = A / (k*x) * tanh(A*k*x) + tR\n",
    "\n",
    "# We can get approximate values for A, k and tR from Palmer et. al. '05\n",
    "# Ranges of parameters to start with:\n",
    "# A: 0.5 - 1\n",
    "# k: 5 - 40\n",
    "# tR: 0.25 - 0.5 (in seconds)\n",
    "# x: 0 - 1\n",
    "\n",
    "# To identify best fit, calculate the likelihood of predicted pC and mRT and find the maximum likelihood.\n",
    "\n",
    "# Likelihood of pC follows a binomial distribution\n",
    "# Lp = n! / (r!(n-r)! * pC(x)^r * (1-pC(x))^(n-r), where\n",
    "# n = # trials, r = # required correct\n",
    "\n",
    "# Likelihood of mRT follows a Gaussian distribution\n",
    "# Lrt = 1 / (SDrt * (sqrt(2*pi))) * e^-((mRT(x) - oRT(x)) / SDrt)^2 * 1/2, where\n",
    "# oRT = observed mRT, mRT = predicted mRT, SDrt = SD of predicted mRT\n",
    "\n",
    "# VARrt = VARtd + VARtr, where\n",
    "# VARtd = variance in decision time, VARtr = variance in residual time. Thus,\n",
    "# VARrt = (A * tanh(A*k*x) - A*k*x * sech(A*k*x)) / (k*x)^3 + (0.1 * tR)^2\n",
    "\n",
    "# Final fit measure is the log likelihood, which is the sum of the likelihoods of accuracy and mean RT, \n",
    "# over all combinations of coherence and distance\n",
    "# Lprt = sigma(x)(ln(Lp(s)) + ln(Lrt(x)))\n",
    "\n",
    "# The first pass of the model will be to estimate values of x without any assumptions about stimulus relationtips.\n",
    "# The stopping point will be the point of least error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## First run of the model. \n",
    "\n",
    "Amin = 0.1\n",
    "kmin = 0.001\n",
    "tRmin = 0\n",
    "\n",
    "# Initialize A, k and tR parameters\n",
    "A, dA = np.linspace(0.1, 3, 10, retstep=True)\n",
    "# k, dk = np.linspace(0.3, 2, 20, retstep=True)\n",
    "k, dk = np.linspace(0.05, 2, 10, retstep=True)\n",
    "tR, dtR = np.linspace(0, 5, 7, retstep=True)\n",
    "\n",
    "As, ks, tRs = np.meshgrid(A, k, tR)\n",
    "As = As.flatten()\n",
    "ks = ks.flatten()\n",
    "tRs = tRs.flatten()\n",
    "\n",
    "# This is the overall number of permutations of A, k and tR being performed\n",
    "nPar = len(As)\n",
    "\n",
    "# Initialize stimulus strength parameter\n",
    "dx = 0.02\n",
    "x = np.arange(0.01, 8, dx)\n",
    "\n",
    "# Initialize arrays that hold predicted accuracies and RTs\n",
    "epc = np.ones((nPar, len(x), nC*nD, nSub)) * -9\n",
    "ert = np.ones((nPar, len(x), nC*nD, nSub)) * -9\n",
    "sdrt = np.ones((nPar, len(x), nC*nD, nSub)) * -9\n",
    "\n",
    "## Initialize the array that holds the\n",
    "# individual likelihood values\n",
    "lpc = np.zeros((nPar, len(x), nC*nD, nSub))\n",
    "lrt = np.zeros((nPar, len(x), nC*nD, nSub))\n",
    "\n",
    "\n",
    "## Now run the model using the parameters defined above\n",
    "\n",
    "# From the set of parameters, calculate the (expected) predicted PC and RT\n",
    "# and then find the likelihood that these estimates match the observed PC and RT\n",
    "for si in range(nSub):\n",
    "    for pi in range(nPar):\n",
    "        for cdi in range(nC*nD):\n",
    "            # Calculate expected accuracy for each coherence-distance combination\n",
    "            epc[pi,:,cdi,si] = 1 / (1 + np.exp(-2 * As[pi] * ks[pi] * abs(x)))\n",
    "            # And the likelihood of this accuracy\n",
    "            lpc[pi,:,cdi,si] = fact(Ns[cdi,si]) / (fact(Rs[cdi,si]) * fact(Ns[cdi,si]-Rs[cdi,si])) * \\\n",
    "                                (epc[pi,:,cdi,si] ** Rs[cdi,si]) * \\\n",
    "                                ((1 - epc[pi,:,cdi,si]) ** (Ns[cdi,si] - Rs[cdi,si]))\n",
    "            \n",
    "            # Calculate expected mean RT for each coherence-distance combination\n",
    "            ert[pi,:,cdi,si] = As[pi] / (ks[pi] * x) * np.tanh(As[pi] * ks[pi] * x) + tRs[pi] \n",
    "            # And standard error of the mean\n",
    "            sdrt[pi,:,cdi,si] = np.sqrt(((As[pi] * np.tanh(As[pi] * ks[pi] * x) - \\\n",
    "                    As[pi] * ks[pi] * x * (1/np.cosh(np.square(As[pi] * ks[pi] * x)))) / \\\n",
    "                    (ks[pi] * x) ** 3 + np.square(0.1 * tRs[pi])) / Ns[cdi,si])\n",
    "            # And the likelihood of observing that RT\n",
    "            lrt[pi,:,cdi,si] = 1 / (sdrt[pi,:,cdi,si] * np.sqrt(2 * np.pi)) * \\\n",
    "                                np.e ** (-1/2 * np.square((ert[pi,:,cdi,si] - mRTs[cdi,si]) / sdrt[pi,:,cdi,si]))\n",
    "\n",
    "# Find the set of best x values for each parameter combination and\n",
    "# then calculate the total log-likelihood for each parameter combination\n",
    "\n",
    "bestXcd = np.ones((nPar, nC*nD, nSub), dtype = np.int) * -9\n",
    "totLL = np.zeros((nPar, nSub))\n",
    "for si in range(nSub):\n",
    "    for pi in range(nPar):\n",
    "        # At each A-k-tR combination, find the index of x value \n",
    "        # that maximizes likelihood for each CD combination\n",
    "        bestXcd[pi,:,si] = np.argmax(lpc[pi,:,:,si] * lrt[pi,:,:,si],0)\n",
    "        for cdi in range(nC*nD):\n",
    "            # Sum over all CDs to obtain overall likelihood for the \n",
    "            # give A-k-tR combination\n",
    "            totLL[pi,si] += np.log(lpc[pi,bestXcd[pi,cdi,si],cdi,si]) + \\\n",
    "                                np.log(lrt[pi,bestXcd[pi,cdi,si],cdi,si])\n",
    "\n",
    "# Find the parameters for which total log-likelihood is maximum\n",
    "# There are some NaN values in the likelihood matrix so exclude those\n",
    "maxParId = np.zeros(nSub, dtype = np.int)\n",
    "\n",
    "# Record the values of best fit x for each CD combination\n",
    "bestx = np.zeros((nC*nD, nSub), dtype = np.int)\n",
    "for si in range(nSub):\n",
    "    maxParId[si] = np.where(totLL[:,si] == np.nanmax(totLL[:,si]))[0]\n",
    "    bestx[:,si] = bestXcd[maxParId[si],:,si]\n",
    "    # print(np.where(maxLLx[:,si] == np.nanmax(maxLLx[:,si]))[0])\n",
    "\n",
    "# Save the parameter values predicting maximum likelihoods for the different \n",
    "# coherence-distance combinations\n",
    "subXs = np.zeros((nC*nD, nSub))\n",
    "#diagFile.write('Best values of A, k and tR in run 1\\n')\n",
    "for si in range(nSub):\n",
    "    subXs[:,si] = x[bestx[:,si]].round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for si in range(nSub):\n",
    "    print(bestx[:,si].reshape((nC,nD)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(x[bestx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## And now for some plots\n",
    "\n",
    "# Plot the total log-likelihood values obtained for each subject\n",
    "plt.figure()\n",
    "for si in range(nSub):\n",
    "    plt.subplot(3,3,si+1)\n",
    "    plt.plot(totLL[:,si],'.')\n",
    "    plt.ylim(-200, 0)\n",
    "    \n",
    "# Plot the observed (behavior) and expected (model) PC and RT\n",
    "for si in range(nSub):\n",
    "    temp = []\n",
    "    ymin = min(pCs[:,si])\n",
    "    ymax = max(pCs[:,si])\n",
    "    for cdi in range(nC*nD):\n",
    "        temp.append(epc[maxParId[si], bestx[cdi,si], cdi, si])\n",
    "    if min(temp) < ymin:\n",
    "        ymin = min(temp)\n",
    "    if max(temp) > ymax:\n",
    "        ymax = max(temp)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.subplot(221)\n",
    "    plt.title(subs[si] + ' Behavior')\n",
    "    plt.plot(np.reshape(pCs[:,si],(nC,nD)),'o-')\n",
    "    plt.ylim((ymin, ymax))\n",
    "    \n",
    "    plt.subplot(222)\n",
    "    plt.title('Model')\n",
    "    plt.plot(np.reshape(temp,(nC,nD)),'o-')\n",
    "    plt.ylim((ymin,ymax))\n",
    "\n",
    "    temp = []\n",
    "    ymin = min(mRTs[:,si])\n",
    "    ymax = max(mRTs[:,si])\n",
    "    for cdi in range(nC*nD):\n",
    "        temp.append(ert[maxParId[si], bestx[cdi,si], cdi, si])\n",
    "    if min(temp) < ymin:\n",
    "        ymin = min(temp)\n",
    "    if max(temp) > ymax:\n",
    "        ymax = max(temp)\n",
    "    \n",
    "    plt.subplot(223)\n",
    "    plt.plot(np.reshape(mRTs[:,si],(nC,nD)),'o-')\n",
    "    plt.ylim((ymin,ymax))\n",
    "    plt.xlabel('Coherence')\n",
    "    \n",
    "    plt.subplot(224)\n",
    "    plt.plot(np.reshape(temp,(nC,nD)),'o-')\n",
    "    plt.ylim((ymin,ymax))\n",
    "    plt.xlabel('Coherence')\n",
    "    \n",
    "    fname = 'run1fit_' + subs[si] + '.eps'\n",
    "    plt.savefig(fname, format = 'eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sumLL = np.zeros((nC*nD, nSub))\n",
    "for si in range(nSub):\n",
    "    sumLL[0,si] = totLL[maxParId[si],si]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sumLL[0,:].round(decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run 2 of the model\n",
    "\n",
    "minA = np.zeros(nSub)\n",
    "maxA = np.zeros(nSub)\n",
    "mink = np.zeros(nSub)\n",
    "maxk = np.zeros(nSub)\n",
    "mintR = np.zeros(nSub)\n",
    "maxtR = np.zeros(nSub)\n",
    "\n",
    "nd = 3 # Number of deltas before and after best fit value\n",
    "\n",
    "for si in range(nSub):\n",
    "    # Set up A, k and tR parameters for the next round of simulations\n",
    "    # Use the bestx values from the first run, don't fit for x again\n",
    "    \n",
    "    # First set the range of all variables. \n",
    "    # minVar = bestValue - dVar*nd : bestValue + dVar*nd\n",
    "    # If the new minimum is <= 0, then set it to the old minimum.\n",
    "    minA[si] = As[maxParId[si]] - nd * dA\n",
    "    maxA[si] = As[maxParId[si]] + nd * dA\n",
    "    if minA[si] < 0:\n",
    "        minA[si] = A[0]\n",
    "    \n",
    "    mink[si] = ks[maxParId[si]] - nd * dk\n",
    "    maxk[si] = ks[maxParId[si]] + nd * dk\n",
    "    if mink[si] < 0:\n",
    "        mink[si] = k[0]\n",
    "        \n",
    "    mintR[si] = tRs[maxParId[si]] - nd * dtR\n",
    "    maxtR[si] = tRs[maxParId[si]] + nd * dtR\n",
    "    if mintR[si] < 0:\n",
    "        mintR[si] = tR[0]\n",
    "\n",
    "# Set up the parameter meshgrid\n",
    "nStep = 9 # Number of values tested, per parameter\n",
    "\n",
    "A = np.zeros((nStep, nSub))\n",
    "dA = np.zeros(nSub)\n",
    "k = np.zeros((nStep, nSub))\n",
    "dk = np.zeros(nSub)\n",
    "tR = np.zeros((nStep, nSub))\n",
    "dtR = np.zeros(nSub)\n",
    "\n",
    "# This is the overall number of permutations of A, k and tR being performed\n",
    "nPar = nStep ** 3\n",
    "\n",
    "As = np.zeros((nPar, nSub))\n",
    "ks = np.zeros((nPar, nSub))\n",
    "tRs = np.zeros((nPar, nSub))\n",
    "\n",
    "for si in range(nSub):\n",
    "    A[:,si], dA[si] = np.linspace(minA[si], maxA[si], nStep, retstep=True)\n",
    "    k[:,si], dk[si] = np.linspace(mink[si], maxk[si], nStep, retstep=True)\n",
    "    tR[:,si], dtR[si] = np.linspace(mintR[si], maxtR[si], nStep, retstep=True)\n",
    "\n",
    "    tempAs, tempks, temptRs = np.meshgrid(A[:,si], k[:,si], tR[:,si])\n",
    "    As[:,si] = tempAs.flatten()\n",
    "    ks[:,si] = tempks.flatten()\n",
    "    tRs[:,si] = temptRs.flatten()\n",
    "    \n",
    "    # Initialize arrays that hold predicted accuracies and RTs\n",
    "    epc = np.ones((nPar, nC*nD, nSub)) * -9\n",
    "    ert = np.ones((nPar, nC*nD, nSub)) * -9\n",
    "    sdrt = np.ones((nPar, nC*nD, nSub)) * -9\n",
    "\n",
    "    ## Initialize the array that holds the\n",
    "    # individual likelihood values\n",
    "    lpc = np.zeros((nPar, nC*nD, nSub))\n",
    "    lrt = np.zeros((nPar, nC*nD, nSub))\n",
    "    \n",
    "# From the set of parameters, calculate the (expected) predicted PC and RT\n",
    "# and then find the likelihood that these estimates match the observed PC and RT\n",
    "for si in range(nSub):\n",
    "    for pi in range(nPar):\n",
    "        for cdi in range(nC*nD):\n",
    "            # Calculate expected accuracy for each coherence-distance combination\n",
    "            epc[pi,cdi,si] = 1 / (1 + np.exp(-2 * As[pi,si] * ks[pi,si] * abs(x[bestx[cdi,si]])))\n",
    "\n",
    "            # Calculate likelihood of accuracy for this CD combination\n",
    "            lpc[pi,cdi,si] = fact(Ns[cdi,si]) / (fact(Rs[cdi,si]) * fact(Ns[cdi,si]-Rs[cdi,si])) * \\\n",
    "                                (epc[pi,cdi,si] ** Rs[cdi,si]) * \\\n",
    "                                ((1 - epc[pi,cdi,si]) ** (Ns[cdi,si] - Rs[cdi,si]))\n",
    "            \n",
    "            # Calculate expected mean RT for each coherence-distance combination\n",
    "            ert[pi,cdi,si] = As[pi,si] / (ks[pi,si] * x[bestx[cdi,si]]) * \\\n",
    "                                np.tanh(As[pi,si] * ks[pi,si] * x[bestx[cdi,si]]) + tRs[pi,si] \n",
    "            # Calculate SD of mean RT \n",
    "            sdrt[pi,cdi,si] = np.sqrt(((As[pi,si] * np.tanh(As[pi,si] * ks[pi,si] * x[bestx[cdi,si]]) - \\\n",
    "                    As[pi,si] * ks[pi,si] * x[bestx[cdi,si]] * \\\n",
    "                    (1/np.cosh(np.square(As[pi,si] * ks[pi,si] * x[bestx[cdi,si]])))) / \\\n",
    "                    (ks[pi,si] * x[bestx[cdi,si]]) ** 3 + np.square(0.1 * tRs[pi,si])) / Ns[cdi,si])\n",
    "            # Calculate likelihood of mean RT for this CD combination\n",
    "            lrt[pi,cdi,si] = 1 / (sdrt[pi,cdi,si] * np.sqrt(2 * np.pi)) * \\\n",
    "                                np.e ** (-1/2 * np.square((ert[pi,cdi,si] - mRTs[cdi,si]) / sdrt[pi,cdi,si]))\n",
    "                \n",
    "# Calculate the total log-likelihood for each parameter combination\n",
    "totLL = np.zeros((nPar, nSub))\n",
    "for si in range(nSub):\n",
    "    for pi in range(nPar):\n",
    "        for cdi in range(nC*nD):\n",
    "            totLL[pi,si] += np.log(lpc[pi,cdi,si]) + np.log(lrt[pi,cdi,si])\n",
    "\n",
    "# Find the parameters for which likelihood is maximum\n",
    "# There are some NaN values in the likelihood matrix so exclude those\n",
    "maxParId = np.zeros(nSub, dtype = np.int)\n",
    "for si in range(nSub):\n",
    "    maxParId[si] = np.where(totLL[:,si] == np.nanmax(totLL[:,si]))[0]\n",
    "    \n",
    "# Make a note of the sum of total LLs of all subjects. Stop the simulation when sumLL\n",
    "# reaches a cutoff point\n",
    "for si in range(nSub):\n",
    "    sumLL[1,si] = totLL[maxParId[si],si]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sumLL[0:2,:].round(decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## And now for some plots\n",
    "\n",
    "# Plot the total log-likelihoods for each subject\n",
    "plt.figure()\n",
    "for si in range(nSub):\n",
    "    plt.subplot(3,3,si+1)\n",
    "    plt.plot(totLL[:,si],'.')\n",
    "    \n",
    "# Plot the observed (behavior) and expected (model) PC and RT\n",
    "for si in range(nSub):\n",
    "    temp = []\n",
    "    ymin = min(pCs[:,si])\n",
    "    ymax = max(pCs[:,si])\n",
    "    for cdi in range(nC*nD):\n",
    "        temp.append(epc[maxParId[si],cdi,si])\n",
    "    if min(temp) < ymin:\n",
    "        ymin = min(temp)\n",
    "    if max(temp) > ymax:\n",
    "        ymax = max(temp)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.subplot(221)\n",
    "    plt.title(subs[si] + ' Behavior')\n",
    "    plt.plot(np.reshape(pCs[:,si],(nC,nD)),'o-')\n",
    "    plt.ylim((ymin, ymax))\n",
    "    \n",
    "    plt.subplot(222)\n",
    "    plt.title('Model')\n",
    "    plt.plot(np.reshape(temp,(nC,nD)),'o-')\n",
    "    plt.ylim((ymin,ymax))\n",
    "\n",
    "    temp = []\n",
    "    ymin = min(mRTs[:,si])\n",
    "    ymax = max(mRTs[:,si])\n",
    "    for cdi in range(nC*nD):\n",
    "        temp.append(ert[maxParId[si],cdi,si])\n",
    "    if min(temp) < ymin:\n",
    "        ymin = min(temp)\n",
    "    if max(temp) > ymax:\n",
    "        ymax = max(temp)\n",
    "    \n",
    "    plt.subplot(223)\n",
    "    plt.plot(np.reshape(mRTs[:,si],(nC,nD)),'o-')\n",
    "    plt.ylim((ymin,ymax))\n",
    "    plt.xlabel('Coherence')\n",
    "    \n",
    "    plt.subplot(224)\n",
    "    plt.plot(np.reshape(temp,(nC,nD)),'o-')\n",
    "    plt.ylim((ymin,ymax))\n",
    "    plt.xlabel('Coherence')\n",
    "    \n",
    "    fname = 'run2fit_' + subs[si] + '.eps'\n",
    "    plt.savefig(fname, format = 'eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the values of the parameters and the likelihoods after the second run\n",
    "pars = np.zeros((3, nSub))\n",
    "lls = np.zeros(nSub)\n",
    "\n",
    "for si in range(nSub):\n",
    "    pars[0,si] = As[maxParId[si],si]\n",
    "    pars[1,si] = ks[maxParId[si],si]\n",
    "    pars[2,si] = tRs[maxParId[si],si]\n",
    "    lls[si] = sumLL[1,si]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run = np.ones(nSub, dtype = np.int) * 2\n",
    "\n",
    "for si in range(nSub):\n",
    "    # Initialize the minimum and maximum values of the parameters\n",
    "    mnA = As[maxParId[si],si] - nd * dA[si]\n",
    "    mxA = As[maxParId[si],si] + nd * dA[si]\n",
    "    if mnA < Amin:\n",
    "        mnA = Amin\n",
    "\n",
    "    mnk = ks[maxParId[si],si] - nd * dk[si]\n",
    "    mxk = ks[maxParId[si],si] + nd * dk[si]\n",
    "    if mnk < kmin:\n",
    "        mnk = kmin\n",
    "\n",
    "    mntR = tRs[maxParId[si],si] - nd * dtR[si]\n",
    "    mxtR = tRs[maxParId[si],si] + nd * dtR[si]\n",
    "    if mntR < tRmin:\n",
    "        mntR = tRmin\n",
    "\n",
    "    A_run = []\n",
    "    k_run = []\n",
    "    tR_run = []\n",
    "    \n",
    "    # This variable keeps track of whether the simulation should continue or not\n",
    "    simStop = 0\n",
    "\n",
    "    while simStop == 0:\n",
    "        if mxA - mnA > 0.01 and mxk - mnk > 0.001 and mxtR - mntR > 0.01:\n",
    "            # Create temporary parameter variables for each simulation run\n",
    "            tA, tdA = np.linspace(mnA, mxA, nStep, retstep=True)\n",
    "            tk, tdk = np.linspace(mnk, mxk, nStep, retstep=True)\n",
    "            ttR, tdtR = np.linspace(mntR, mxtR, nStep, retstep=True)\n",
    "\n",
    "            tempAs, tempks, temptRs = np.meshgrid(tA, tk, ttR)\n",
    "            tAs = tempAs.flatten()\n",
    "            tks = tempks.flatten()\n",
    "            ttRs = temptRs.flatten()\n",
    "\n",
    "            # Initialize arrays that hold predicted accuracies and RTs\n",
    "            epc = np.ones((nPar, nC*nD)) * -9\n",
    "            ert = np.ones((nPar, nC*nD)) * -9\n",
    "            sdrt = np.ones((nPar, nC*nD)) * -9\n",
    "\n",
    "            ## Initialize the array that holds the individual and total likelihood values\n",
    "            lpc = np.zeros((nPar, nC*nD))\n",
    "            lrt = np.zeros((nPar, nC*nD))\n",
    "            totLL = np.zeros(nPar)\n",
    "\n",
    "            # From the set of parameters, calculate the (expected) predicted PC and RT\n",
    "            # and then find the likelihood that these estimates match the observed PC and RT\n",
    "            for pi in range(nPar):\n",
    "                # Calculate expected accuracy and RT for each coherence-distance combination\n",
    "                epc[pi,:] = 1 / (1 + np.exp(-2 * tAs[pi] * tks[pi] * abs(x[bestx[:,si]])))\n",
    "                ert[pi,:] = tAs[pi] / (tks[pi] * x[bestx[:,si]]) * np.tanh(tAs[pi] * tks[pi] * x[bestx[:,si]]) + ttRs[pi] \n",
    "                for cdi in range(nC*nD):\n",
    "                    # Calculate likelihood of accuracy for this CD combination\n",
    "                    lpc[pi,cdi] = fact(Ns[cdi,si]) / (fact(Rs[cdi,si]) * fact(Ns[cdi,si]-Rs[cdi,si])) * \\\n",
    "                                        (epc[pi,cdi] ** Rs[cdi,si]) * \\\n",
    "                                        ((1 - epc[pi,cdi]) ** (Ns[cdi,si] - Rs[cdi,si]))\n",
    "\n",
    "                    # Calculate SD of mean RT \n",
    "                    sdrt[pi,cdi] = np.sqrt(((tAs[pi] * np.tanh(tAs[pi] * tks[pi] * x[bestx[cdi,si]]) - \\\n",
    "                                             tAs[pi] * tks[pi] * x[bestx[cdi,si]] * \\\n",
    "                                             (1/np.cosh(np.square(tAs[pi] * tks[pi] * x[bestx[cdi,si]])))) / \\\n",
    "                                            (tks[pi] * x[bestx[cdi,si]]) ** 3 + np.square(0.1 * ttRs[pi])) / Ns[cdi,si])\n",
    "\n",
    "                    # Calculate likelihood of mean RT for this CD combination\n",
    "                    lrt[pi,cdi] = 1 / (sdrt[pi,cdi] * np.sqrt(2 * np.pi)) * \\\n",
    "                                        np.e ** (-1/2 * np.square((ert[pi,cdi] - mRTs[cdi,si]) / sdrt[pi,cdi]))\n",
    "\n",
    "                # Calculate the total log-likelihood for each parameter combination\n",
    "                totLL[pi] = np.sum(np.log(lpc[pi,:])) + np.sum(np.log(lrt[pi,:]))\n",
    "\n",
    "            # Find the parameters for which likelihood is maximum\n",
    "            # There are some NaN values in the likelihood matrix so exclude those\n",
    "            ids = np.where(totLL == np.nanmax(totLL))[0]\n",
    "            if len(ids) == 0:\n",
    "                simStop = 1\n",
    "            elif len(ids) > 1:\n",
    "                parId = ids[0]\n",
    "            else:\n",
    "                parId = ids\n",
    "\n",
    "            # Check to see if the simulation should continue for another run\n",
    "            if simStop == 1 or \\\n",
    "            (totLL[parId] > sumLL[run[si]-1,si] and abs(sumLL[run[si]-1,si] - totLL[parId]) <= 0.1) or \\\n",
    "            (totLL[parId] < sumLL[run[si]-1,si] and abs(sumLL[run[si]-1,si] - totLL[parId]) > 15):\n",
    "                simStop = 1\n",
    "            else:\n",
    "                sumLL[run[si],si] = totLL[parId]\n",
    "                run[si] += 1\n",
    "\n",
    "            A_run.append(tAs[parId])\n",
    "            k_run.append(tks[parId])\n",
    "            tR_run.append(ttRs[parId])\n",
    "\n",
    "            # Re-initialize the minimum and maximum values of parameters for the next run\n",
    "            mnA = tAs[parId].round(decimals=3) - nd * tdA.round(decimals=3)\n",
    "            mxA = tAs[parId].round(decimals=3) + nd * tdA.round(decimals=3)\n",
    "\n",
    "            mnk = tks[parId].round(decimals=3) - nd * tdk.round(decimals=3)\n",
    "            mxk = tks[parId].round(decimals=3) + nd * tdk.round(decimals=3)\n",
    "\n",
    "            mntR = ttRs[parId].round(decimals=3) - nd * tdtR.round(decimals=3)\n",
    "            mxtR = ttRs[parId].round(decimals=3) + nd * tdtR.round(decimals=3)\n",
    "\n",
    "            if mnA < Amin:\n",
    "                mnA = Amin\n",
    "            if mnk < kmin:\n",
    "                mnk = kmin\n",
    "            if mntR < tRmin:\n",
    "                mntR = tRmin\n",
    "        else:\n",
    "            simStop = 1\n",
    "            \n",
    "    if run[si] > 2:\n",
    "        pars[0,si] = A_run[-1]\n",
    "        pars[1,si] = k_run[-1]\n",
    "        pars[2,si] = tR_run[-1]\n",
    "        lls[si] = sumLL[run[si]-1,si]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sumLL.round(decimals=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lls.round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(lls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for si in range(nSub):\n",
    "    pcFit = np.zeros((nC,nD))\n",
    "    pcFit = np.zeros((nC,nD))\n",
    "    rtFit = np.zeros((nC,nD))\n",
    "    rtFit = np.zeros((nC,nD))\n",
    "    \n",
    "    temp = 1 / (1 + np.exp(-2 * pars[0,si] * pars[1,si] * abs(x[bestx[:,si]])))\n",
    "    pcFit = temp.reshape((nC,nD))\n",
    "    temp = pars[0,si] / (pars[1,si] * x[bestx[:,si]]) * np.tanh(pars[0,si] * pars[1,si] * x[bestx[:,si]]) + pars[2,si]\n",
    "    rtFit = temp.reshape((nC,nD))\n",
    "        \n",
    "    ymin = 0.3\n",
    "    ymax = 1.1\n",
    "    plt.figure()\n",
    "    plt.subplot(221)\n",
    "    plt.plot(pCs[:,si].reshape((nC,nD)),'o-')\n",
    "    plt.ylim((ymin,ymax))\n",
    "    plt.subplot(222)\n",
    "    plt.plot(pcFit,'o-')\n",
    "    plt.ylim((ymin,ymax))\n",
    "    \n",
    "    ymin = 0.6\n",
    "    ymax = 3\n",
    "    plt.subplot(223)\n",
    "    plt.plot(mRTs[:,si].reshape((nC,nD)),'o-')\n",
    "    plt.ylim((ymin,ymax))\n",
    "    plt.subplot(224)\n",
    "    plt.plot(rtFit,'o-')\n",
    "    plt.ylim((ymin,ymax))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Final A values for each subject\n",
    "pars[0,:].round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Final k values for each subject\n",
    "pars[1,:].round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Final tR values for each subject\n",
    "pars[2,:].round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract group behavioral data (PC, mean and SD of RT, # trials) from csv file\n",
    "# csvFile = '../Data/Behavior/All_behavData.csv'\n",
    "# behavData = pd.read_csv(csvFile, header=None)\n",
    "\n",
    "# Split the file in PC, mean RT and SD RT\n",
    "# Flatten each subject's values for ease of programming\n",
    "pCs = np.mean(pCs, axis = 1)\n",
    "mRTs = np.mean(mRTs, axis = 1)\n",
    "\n",
    "# Get the model fits of PC and mRT for each subject\n",
    "fitPC = np.zeros((nC*nD,9))\n",
    "fitRT = np.zeros((nC*nD,9))\n",
    "for si in range(nSub):\n",
    "    fitPC[:,si] = epc[maxParId[si],:,si]\n",
    "    fitRT[:,si] = ert[maxParId[si],:,si]\n",
    "\n",
    "mfitPC = np.mean(fitPC,1)\n",
    "sdfitPC = np.std(fitPC,1)\n",
    "mfitRT = np.mean(fitRT,1)\n",
    "sdfitRT = np.std(fitRT,1)\n",
    "\n",
    "ymin = np.min(pCs)\n",
    "if ymin > np.min(mfitPC):\n",
    "    ymin = np.min(mfitPC)\n",
    "ymax = np.max(pCs)\n",
    "if ymax < np.max(mfitPC):\n",
    "    ymax = np.max(mfitPC)\n",
    "\n",
    "ids = np.array([0, 5, 10, 15], dtype = np.int)\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.title('Group behavior')\n",
    "plt.plot(pCs,'o-')\n",
    "plt.ylim((ymin - max(sdfitPC), ymax + max(sdfitPC)))\n",
    "plt.subplot(222)\n",
    "plt.title('Average fit')\n",
    "for cdi in range(5):\n",
    "    plt.errorbar(x = range(4), y = mfitPC[[ids + cdi]], yerr = sdfitPC[[ids + cdi]], fmt = 'o-')\n",
    "plt.ylim((ymin - max(sdfitPC), ymax + max(sdfitPC)))\n",
    "\n",
    "ymin = np.min(mRTs)\n",
    "if ymin > np.min(mfitRT):\n",
    "    ymin = np.min(mfitRT)\n",
    "ymax = np.max(mRTs)\n",
    "if ymax < np.max(mfitRT):\n",
    "    ymax = np.max(mfitRT)\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.plot(np.reshape(mRTs,(4,5)),'o-')\n",
    "plt.ylim((ymin - max(sdfitRT), ymax + max(sdfitRT)))\n",
    "plt.xlabel('Coherence')\n",
    "plt.subplot(224)\n",
    "for cdi in range(5):\n",
    "    plt.errorbar(x = range(4), y = mfitRT[[ids + cdi]], yerr = sdfitRT[[ids + cdi]], fmt = 'o-')\n",
    "plt.xlabel('Coherence')\n",
    "plt.ylim((ymin - max(sdfitRT), ymax + max(sdfitRT)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epc[maxParId[si],si]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxParId[si]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
