{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is the basic proportional rate diffusion model from Palmer, Huk and Shadlen '05. \n",
    "# However, rather than fitting all 20 CD combinations at once, I fit \n",
    "# - all coherences at each distance\n",
    "# - all distances at each coherence\n",
    "\n",
    "# I fit all parameters for each parametric condition\n",
    "# After the first step of finding likelihoods for every A, k, tR and x combination,\n",
    "# I organize the A, k, tRs by k.\n",
    "# Then, for each A, tR combination, I find the best k.\n",
    "# Finally, I find the best A, tR, k combination.\n",
    "# I then find better estimates of A, k and tR.\n",
    "\n",
    "# In this version I am including all coherences but only distances of 0, ID (intermediate) and 45.\n",
    "# This is in response to a reviewer saying that the presence of 3 distances that evoke similar\n",
    "# behavior biases the model in favour of distance. \n",
    "\n",
    "# I am imposing the constraint that all parameters be positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## These are the pre-modelling steps where behavioral data is extracted from files.\n",
    "\n",
    "# Load all required libraries\n",
    "% matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from math import factorial as fact\n",
    "# List subjects to fit\n",
    "subs = ['Sub01', 'Sub02', 'Sub04', 'Sub05', 'Sub06', 'Sub08', 'Sub10', 'Sub11', 'Sub13']\n",
    "nSub = len(subs)\n",
    "\n",
    "# Define number of coherences per distance\n",
    "nC = 4\n",
    "# Define number of distances per coherence\n",
    "nD = 4\n",
    "\n",
    "# Initialize arrays to hold PC, mean and SD of RT, and # trials \n",
    "# for each coherence-distanct combination\n",
    "# These values are obtained from the .csv files\n",
    "pCs = np.zeros((nC*nD, nSub))\n",
    "mRTs = np.zeros((nC*nD, nSub))\n",
    "sdRTs = np.zeros((nC*nD, nSub))\n",
    "Ns = np.zeros((nC*nD, nSub))\n",
    "\n",
    "# Initialise a variable to hold # correct trials\n",
    "# This will be computed from Ns and pCs\n",
    "Rs = np.zeros((nC*nD, nSub))\n",
    "\n",
    "# Extract behavioral data (PC, mean and SD of RT, # trials) from csv files\n",
    "for si in range(nSub):\n",
    "    csvFile = '../Data/Behavior/' + subs[si] + '_behavData.csv'\n",
    "    behavData = pd.read_csv(csvFile, header=None)\n",
    "    \n",
    "    # Split the file in PC, mean RT and SD RT\n",
    "    # Flatten each subject's values for ease of programming\n",
    "    temp = np.array(behavData[0:4])\n",
    "    pCs[:,si] = temp[:,0:4].flatten()\n",
    "    temp = np.array(behavData[4:8])\n",
    "    mRTs[:,si] = temp[:,0:4].flatten()\n",
    "    temp = np.array(behavData[8:12])\n",
    "    sdRTs[:,si] = temp[:,0:4].flatten()\n",
    "    temp = np.array(behavData[12:])\n",
    "    Ns[:,si] = temp[:,0:4].flatten()\n",
    "    Rs[:,si] = np.round(Ns[:,si] * pCs[:,si])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters to fit:\n",
    "# A: Boundary\n",
    "# x: Stimulus strength\n",
    "# k: Proportionality constant (Stim. str. = kx)\n",
    "# tR: Residual time\n",
    "\n",
    "# Equations to fit for each stimulus strength:\n",
    "# pC = 1 / (1+exp(-2*A*k*abs(x)))\n",
    "# mRT = A / (k*x) * tanh(A*k*x) + tR\n",
    "\n",
    "# We can get approximate values for A, k and tR from Palmer et. al. '05\n",
    "# Ranges of parameters to start with:\n",
    "# A: 0.5 - 1\n",
    "# k: 5 - 40\n",
    "# tR: 0.25 - 0.5 (in seconds)\n",
    "# x: 0 - 1\n",
    "\n",
    "# To identify best fit, calculate the likelihood of predicted pC and mRT and find the maximum likelihood.\n",
    "\n",
    "# Likelihood of pC follows a binomial distribution\n",
    "# Lp = n! / (r!(n-r)! * pC(x)^r * (1-pC(x))^(n-r), where\n",
    "# n = # trials, r = # required correct\n",
    "\n",
    "# Likelihood of mRT follows a Gaussian distribution\n",
    "# Lrt = 1 / (SDrt * (sqrt(2*pi))) * e^-((mRT(x) - oRT(x)) / SDrt)^2 * 1/2, where\n",
    "# oRT = observed mRT, mRT = predicted mRT, SDrt = SD of predicted mRT\n",
    "\n",
    "# VARrt = VARtd + VARtr, where\n",
    "# VARtd = variance in decision time, VARtr = variance in residual time. Thus,\n",
    "# VARrt = (A * tanh(A*k*x) - A*k*x * sech(A*k*x)) / (k*x)^3 + (0.1 * tR)^2\n",
    "\n",
    "# Final fit measure is the log likelihood, which is the sum of the likelihoods of accuracy and mean RT, \n",
    "# over all combinations of coherence and distance\n",
    "# Lprt = sigma(x)(ln(Lp(s)) + ln(Lrt(x)))\n",
    "\n",
    "# The first pass of the model will be to estimate values of x without any assumptions about stimulus relationtips.\n",
    "# The stopping point will be the point of least error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## First run of the model. Stage 1:\n",
    "\n",
    "Amin = 0.5\n",
    "kmin = 0.001\n",
    "tRmin = 0\n",
    "\n",
    "# Initialize A, k and tR parameters\n",
    "A_coh, dA_coh = np.linspace(Amin, 5, 10, retstep=True)\n",
    "k_coh, dk_coh = np.linspace(kmin, 3, 10, retstep=True)\n",
    "tR_coh, dtR_coh = np.linspace(tRmin, 2, 10, retstep=True)\n",
    "\n",
    "A_dist, dA_dist = np.linspace(Amin, 5, 10, retstep=True)\n",
    "k_dist, dk_dist = np.linspace(kmin, 3, 10, retstep=True)\n",
    "tR_dist, dtR_dist = np.linspace(tRmin, 2, 10, retstep=True)\n",
    "\n",
    "\n",
    "As_coh, tRs_coh, ks_coh = np.meshgrid(A_coh, tR_coh, k_coh)\n",
    "As_coh = As_coh.flatten()\n",
    "tRs_coh = tRs_coh.flatten()\n",
    "ks_coh = ks_coh.flatten()\n",
    "As_dist, tRs_dist, ks_dist = np.meshgrid(A_dist, tR_dist, k_dist)\n",
    "As_dist = As_dist.flatten()\n",
    "tRs_dist = tRs_dist.flatten()\n",
    "ks_dist = ks_dist.flatten()\n",
    "\n",
    "# This is the overall number of permutations of A, k and tR being performed\n",
    "nPar = len(As_coh)\n",
    "nK = len(k_coh)\n",
    "\n",
    "# Initialize stimulus strength parameter\n",
    "dx = 0.02\n",
    "x_coh = np.arange(0.01, 8, dx)\n",
    "x_dist = np.arange(0.01, 5, dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dA_coh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(x_coh.shape, x_dist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize arrays that hold predicted accuracies and RTs\n",
    "epc_coh_hi_d = np.ones((nPar, len(x_coh), nC, nSub)) * -9\n",
    "ert_coh_hi_d = np.ones((nPar, len(x_coh), nC, nSub)) * -9\n",
    "sdrt_coh_hi_d = np.ones((nPar, len(x_coh), nC, nSub)) * -9\n",
    "epc_dist_hi_c = np.ones((nPar, len(x_dist), nD, nSub)) * -9\n",
    "ert_dist_hi_c = np.ones((nPar, len(x_dist), nD, nSub)) * -9\n",
    "sdrt_dist_hi_c = np.ones((nPar, len(x_dist), nD, nSub)) * -9\n",
    "\n",
    "## Initialize the array that holds the\n",
    "# individual likelihood values\n",
    "lpc_coh_hi_d = np.zeros((nPar, len(x_coh), nC, nSub))\n",
    "lrt_coh_hi_d = np.zeros((nPar, len(x_coh), nC, nSub))\n",
    "lpc_dist_hi_c = np.zeros((nPar, len(x_dist), nD, nSub))\n",
    "lrt_dist_hi_c = np.zeros((nPar, len(x_dist), nD, nSub))\n",
    "\n",
    "## Now find the set of xs for \n",
    "# - All coherences at high distance, and\n",
    "# - All distances at high coherence\n",
    "\n",
    "for pi in range(nPar):\n",
    "    # Calculate expected accuracy for each coherence-distance combination\n",
    "    epcs = 1 / (1 + np.exp(-2 * As_coh[pi] * ks_coh[pi] * abs(x_coh)))\n",
    "    temp = np.repeat(epcs,  nC * nSub, axis=0)\n",
    "    epc_coh_hi_d[pi,...] = np.reshape(temp, (len(epcs), nC, nSub))\n",
    "    \n",
    "    epcs = 1 / (1 + np.exp(-2 * As_dist[pi] * ks_dist[pi] * abs(x_dist)))\n",
    "    temp = np.repeat(epcs,  nD * nSub, axis=0)\n",
    "    epc_dist_hi_c[pi,...] = np.reshape(temp, (len(epcs), nD, nSub))\n",
    "    \n",
    "    # Calculate expected mean RT for each coherence-distance combination\n",
    "    erts = As_coh[pi] / (ks_coh[pi] * x_coh) * np.tanh(As_coh[pi] * ks_coh[pi] * x_coh) + tRs_coh[pi] \n",
    "    temp = np.repeat(erts,  nC * nSub, axis=0)\n",
    "    ert_coh_hi_d[pi,...] = np.reshape(temp, (len(erts), nC, nSub))\n",
    "    \n",
    "    erts = As_dist[pi] / (ks_dist[pi] * x_dist) * np.tanh(As_dist[pi] * ks_dist[pi] * x_dist) + tRs_dist[pi] \n",
    "    temp = np.repeat(erts,  nD * nSub, axis=0)\n",
    "    ert_dist_hi_c[pi,...] = np.reshape(temp, (len(erts), nD, nSub))\n",
    "    \n",
    "    for si in range(nSub):\n",
    "        # Find the likelihood that the estimates calculated above match the observed PC and RT\n",
    "        # for all coherences at each distance\n",
    "        di = nD - 1\n",
    "        for ci in range(nC):\n",
    "            # Calculate the likelihood of accuracy\n",
    "            lpc_coh_hi_d[pi,:,ci,si] = fact(Ns[ci*nD+di,si]) / (fact(Rs[ci*nD+di,si]) * \\\n",
    "                                                         fact(Ns[ci*nD+di,si]-Rs[ci*nD+di,si])) * \\\n",
    "                                (epc_coh_hi_d[pi,:,ci,si] ** Rs[ci*nD+di,si]) * \\\n",
    "                                ((1 - epc_coh_hi_d[pi,:,ci,si]) ** (Ns[ci*nD+di,si] - Rs[ci*nD+di,si]))\n",
    "\n",
    "            # Calculate the standard error of mean ert\n",
    "            sdrt_coh_hi_d[pi,:,ci,si] = np.sqrt(((As_coh[pi] * np.tanh(As_coh[pi] * ks_coh[pi] * x_coh) - \\\n",
    "                    As_coh[pi] * ks_coh[pi] * x_coh * (1/np.cosh(np.square(As_coh[pi] * ks_coh[pi] * x_coh)))) / \\\n",
    "                    (ks_coh[pi] * x_coh) ** 3 + np.square(0.1 * tRs_coh[pi])) / Ns[ci*nD+di,si])\n",
    "            # Calculate the likelihood of RT\n",
    "            lrt_coh_hi_d[pi,:,ci,si] = 1 / (sdrt_coh_hi_d[pi,:,ci,si] * np.sqrt(2 * np.pi)) * \\\n",
    "                                np.e ** (-1/2 * np.square((ert_coh_hi_d[pi,:,ci,si] - mRTs[ci*nD+di,si]) / \\\n",
    "                                                          sdrt_coh_hi_d[pi,:,ci,si]))\n",
    "\n",
    "        # Find the likelihood that the estimates calculated above match the observed PC and RT\n",
    "        # for all distances at each coherence\n",
    "        ci = nC - 1\n",
    "        for di in range(nD):\n",
    "            # Calculate the likelihood of this accuracy\n",
    "            lpc_dist_hi_c[pi,:,di,si] = fact(Ns[ci*nD+di,si]) / (fact(Rs[ci*nD+di,si]) * \\\n",
    "                                                                fact(Ns[ci*nD+di,si]-Rs[ci*nD+di,si])) * \\\n",
    "                                (epc_dist_hi_c[pi,:,di,si] ** Rs[ci*nD+di,si]) * \\\n",
    "                                ((1 - epc_dist_hi_c[pi,:,di,si]) ** (Ns[ci*nD+di,si] - Rs[ci*nD+di,si]))\n",
    "\n",
    "            # Calculate the standard error of mean ert\n",
    "            sdrt_dist_hi_c[pi,:,di,si] = np.sqrt(((As_dist[pi] * np.tanh(As_dist[pi] * ks_dist[pi] * x_dist) - \\\n",
    "                    As_dist[pi] * ks_dist[pi] * x_dist * (1/np.cosh(np.square(As_dist[pi] * ks_dist[pi] * x_dist)))) / \\\n",
    "                    (ks_dist[pi] * x_dist) ** 3 + np.square(0.1 * tRs_dist[pi])) / Ns[ci*nD+di,si])\n",
    "            # Calculate the likelihood of observing that RT\n",
    "            lrt_dist_hi_c[pi,:,di,si] = 1 / (sdrt_dist_hi_c[pi,:,di,si] * np.sqrt(2 * np.pi)) * \\\n",
    "                                np.e ** (-1/2 * np.square((ert_dist_hi_c[pi,:,di,si] - mRTs[ci*nD+di,si]) / \\\n",
    "                                                          sdrt_dist_hi_c[pi,:,di,si]))\n",
    "\n",
    "# Find the set of best x values for all coherence at each distance and vice versa.\n",
    "# Then calculate the total log-likelihood for each parameter combination\n",
    "\n",
    "bestXcd_coh_d = np.ones((nPar, nC, nSub), dtype = np.int) * -9\n",
    "bestXcd_dist_c = np.ones((nPar, nD, nSub), dtype = np.int) * -9\n",
    "\n",
    "ll_coh_d = np.zeros((nPar, nSub))\n",
    "ll_dist_c = np.zeros((nPar, nSub))\n",
    "\n",
    "for si in range(nSub):\n",
    "    for pi in range(nPar):\n",
    "        # At each A-k-tR combination, find the index of x value \n",
    "        # that maximizes likelihood for each CD combination\n",
    "        di = nD - 1\n",
    "        bestXcd_coh_d[pi,:,si] = np.argmax(lpc_coh_hi_d[pi,:,:,si] * lrt_coh_hi_d[pi,:,:,si],0)\n",
    "        for ci in range(nC):\n",
    "            ll_coh_d[pi,si] += np.log(lpc_coh_hi_d[pi,bestXcd_coh_d[pi,ci,si],ci,si]) + \\\n",
    "                                  np.log(lrt_coh_hi_d[pi,bestXcd_coh_d[pi,ci,si],ci,si])\n",
    "\n",
    "        # At each A-k-tR combination, find the index of x value \n",
    "        # that maximizes likelihood for each CD combination\n",
    "        ci = nC - 1\n",
    "        bestXcd_dist_c[pi,:,si] = np.argmax(lpc_dist_hi_c[pi,:,:,si] * lrt_dist_hi_c[pi,:,:,si],0)\n",
    "        for di in range(nD):\n",
    "            ll_dist_c[pi,si] += np.log(lpc_dist_hi_c[pi,bestXcd_dist_c[pi,di,si],di,si]) + \\\n",
    "                                   np.log(lrt_dist_hi_c[pi,bestXcd_dist_c[pi,di,si],di,si])\n",
    "                \n",
    "# The next step is to maximize over k (i.e., every set of 10 nPars)\n",
    "nK = len(k_coh)\n",
    "k_coh_d = np.ones((int(nPar/nK), nD, nSub), dtype = int) * -9\n",
    "k_dist_c = np.ones((int(nPar/nK), nC, nSub), dtype = int) * -9\n",
    "\n",
    "totLL_coh_d = np.zeros((int(nPar/nK), nD, nSub))\n",
    "totLL_dist_c = np.zeros((int(nPar/nK), nC, nSub))\n",
    "\n",
    "for si in range(nSub):\n",
    "    for pi in range(0, nPar, nK):\n",
    "        di = nD - 1\n",
    "        # Find the best k for each A-tR combination\n",
    "        bestK = np.argmax(ll_coh_d[pi:pi+nK,si])\n",
    "        k_coh_d[int(pi/nK),di,si] = bestK\n",
    "        # And find the likelihood at that K for each A-tR combination\n",
    "        totLL_coh_d[int(pi/nK),di,si] = ll_coh_d[pi+bestK,si]\n",
    "\n",
    "        ci = nC - 1\n",
    "        # Find the best k for each A-tR combination\n",
    "        bestK = np.argmax(ll_dist_c[pi:pi+nK,si])\n",
    "        k_dist_c[int(pi/nK),ci,si] = bestK\n",
    "        # And find the likelihood at that K for each A-tR combination\n",
    "        totLL_dist_c[int(pi/nK),ci,si] = ll_dist_c[pi+bestK,si]\n",
    "        \n",
    "# Find the parameters for which total log-likelihood is maximum\n",
    "# There are some NaN values in the likelihood matrix so exclude those\n",
    "maxParId_coh_d = np.zeros((nD, nSub), dtype = np.int)\n",
    "maxParId_dist_c = np.zeros((nC, nSub), dtype = np.int)\n",
    "\n",
    "# Record the values of best fit x for each CD combination\n",
    "bestx_coh_d = np.zeros((nC, nSub), dtype = np.int)\n",
    "bestx_dist_c = np.zeros((nD, nSub), dtype = np.int)\n",
    "bestk_coh_d = np.zeros((nD, nSub))\n",
    "bestk_dist_c = np.zeros((nC, nSub))\n",
    "for si in range(nSub):\n",
    "    di = nD - 1\n",
    "    ids = np.where(totLL_coh_d[:,di,si] == np.nanmax(totLL_coh_d[:,di,si]))[0]\n",
    "    if len(ids) > 1:\n",
    "        maxParId_coh_d[di,si] = ids[0]\n",
    "    else:\n",
    "        maxParId_coh_d[di,si] = ids\n",
    "    bestx_coh_d[:,si] = bestXcd_coh_d[maxParId_coh_d[di,si]*nK+k_coh_d[maxParId_coh_d[di,si],di,si],:,si]\n",
    "    bestk_coh_d[di,si] = k_coh[k_coh_d[maxParId_coh_d[di,si],di,si]]\n",
    "\n",
    "    ci = nC - 1\n",
    "    ids = np.where(totLL_dist_c[:,ci,si] == np.nanmax(totLL_dist_c[:,ci,si]))[0]\n",
    "    if len(ids) > 1:\n",
    "        maxParId_dist_c[ci,si] = ids[0]\n",
    "    else:\n",
    "        maxParId_dist_c[ci,si] = ids\n",
    "    bestx_dist_c[:,si] = bestXcd_dist_c[maxParId_dist_c[ci,si]*nK+k_dist_c[maxParId_dist_c[ci,si],ci,si],:,si]\n",
    "    bestk_dist_c[ci,si] = k_dist[k_dist_c[maxParId_dist_c[ci,si],ci,si]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(bestx_coh_d)\n",
    "print(bestx_dist_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(x_coh[bestx_coh_d])\n",
    "print(x_dist[bestx_dist_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize arrays that hold predicted accuracies and RTs\n",
    "epc_coh_d = np.ones((nPar, nD-1, nC, nSub)) * -9\n",
    "ert_coh_d = np.ones((nPar, nD-1, nC, nSub)) * -9\n",
    "sdrt_coh_d = np.ones((nPar, nD-1, nC, nSub)) * -9\n",
    "epc_dist_c = np.ones((nPar, nC-1, nD, nSub)) * -9\n",
    "ert_dist_c = np.ones((nPar, nC-1, nD, nSub)) * -9\n",
    "sdrt_dist_c = np.ones((nPar, nC-1, nD, nSub)) * -9\n",
    "\n",
    "## Initialize the array that holds the\n",
    "# individual likelihood values\n",
    "lpc_coh_d = np.zeros((nPar, nD-1, nC, nSub))\n",
    "lrt_coh_d = np.zeros((nPar, nD-1, nC, nSub))\n",
    "lpc_dist_c = np.zeros((nPar, nC-1, nD, nSub))\n",
    "lrt_dist_c = np.zeros((nPar, nC-1, nD, nSub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Now find the set of A, k, tR for \n",
    "# - All coherences at distances other than high distance, and\n",
    "# - All distances at coherences other than high coherence\n",
    "\n",
    "for pi in range(nPar):\n",
    "    for si in range(nSub):\n",
    "        # Find the likelihood that the estimates calculated above match the observed PC and RT\n",
    "        # for all coherences at each distance\n",
    "        for di in range(nD-1):\n",
    "            # Calculate expected accuracy and RT \n",
    "            epc_coh_d[pi,di,:,si] = 1 / (1 + np.exp(-2 * As_coh[pi] * ks_coh[pi] * x_coh[bestx_coh_d[:,si]]))\n",
    "            ert_coh_d[pi,di,:,si]= As_coh[pi] / (ks_coh[pi] * x_coh[bestx_coh_d[:,si]]) * np.tanh(As_coh[pi] * \\\n",
    "                                                            ks_coh[pi] * x_coh[bestx_coh_d[:,si]]) + tRs_coh[pi] \n",
    "            for ci in range(nC):    \n",
    "                # Calculate the likelihood of accuracy\n",
    "                lpc_coh_d[pi,di,ci,si] = fact(Ns[ci*nD+di,si]) / (fact(Rs[ci*nD+di,si]) * \\\n",
    "                                    fact(Ns[ci*nD+di,si] - Rs[ci*nD+di,si])) * (epc_coh_d[pi,di,ci,si] ** Rs[ci*nD+di,si]) * \\\n",
    "                                    ((1 - epc_coh_d[pi,di,ci,si]) ** (Ns[ci*nD+di,si] - Rs[ci*nD+di,si]))\n",
    "\n",
    "                # Calculate the standard error of mean ert\n",
    "                sdrt_coh_d[pi,di,ci,si] = np.sqrt(((As_coh[pi] * np.tanh(As_coh[pi] * ks_coh[pi] * \\\n",
    "                                                                         x_coh[bestx_coh_d[ci,si]]) - \\\n",
    "                                        As_coh[pi] * ks_coh[pi] * x_coh[bestx_coh_d[ci,si]] * \\\n",
    "                                        (1/np.cosh(np.square(As_coh[pi] * ks_coh[pi] * x_coh[bestx_coh_d[ci,si]])))) / \\\n",
    "                        (ks_coh[pi] * x_coh[bestx_coh_d[ci,si]]) ** 3 + np.square(0.1 * tRs_coh[pi])) / Ns[ci*nD+di,si])\n",
    "                # Calculate the likelihood of RT\n",
    "                lrt_coh_d[pi,di,ci,si] = 1 / (sdrt_coh_d[pi,di,ci,si] * np.sqrt(2 * np.pi)) * \\\n",
    "                                    np.e ** (-1/2 * np.square((ert_coh_d[pi,di,ci,si] - mRTs[ci*nD+di,si]) / \\\n",
    "                                                              sdrt_coh_d[pi,di,ci,si]))\n",
    "\n",
    "        # Find the likelihood that the estimates calculated above match the observed PC and RT\n",
    "        # for all distances at each coherence\n",
    "        for ci in range(nC-1):\n",
    "            # Calculate expected accuracy and RT \n",
    "            epc_dist_c[pi,ci,:,si] = 1 / (1 + np.exp(-2 * As_dist[pi] * ks_dist[pi] * x_dist[bestx_dist_c[:,si]]))\n",
    "            ert_dist_c[pi,ci,:,si]= As_dist[pi] / (ks_dist[pi] * x_dist[bestx_dist_c[:,si]]) * np.tanh(As_dist[pi] * \\\n",
    "                                                                ks_dist[pi] * x_dist[bestx_dist_c[:,si]]) + tRs_dist[pi] \n",
    "            for di in range(nD):\n",
    "                # Calculate the likelihood of this accuracy\n",
    "                lpc_dist_c[pi,ci,di,si] = fact(Ns[ci*nD+di,si]) / (fact(Rs[ci*nD+di,si]) * \\\n",
    "                                                                    fact(Ns[ci*nD+di,si]-Rs[ci*nD+di,si])) * \\\n",
    "                                    (epc_dist_c[pi,ci,di,si] ** Rs[ci*nD+di,si]) * \\\n",
    "                                    ((1 - epc_dist_c[pi,ci,di,si]) ** (Ns[ci*nD+di,si] - Rs[ci*nD+di,si]))\n",
    "\n",
    "                # Calculate the standard error of mean ert\n",
    "                sdrt_dist_c[pi,ci,di,si] = np.sqrt(((As_dist[pi] * np.tanh(As_dist[pi] * ks_dist[pi] * \\\n",
    "                                                                           x_dist[bestx_dist_c[di,si]]) - \\\n",
    "                                            As_dist[pi] * ks_dist[pi] * x_dist[bestx_dist_c[di,si]] * \\\n",
    "                                        (1/np.cosh(np.square(As_dist[pi] * ks_dist[pi] * x_dist[bestx_dist_c[di,si]])))) / \\\n",
    "                        (ks_dist[pi] * x_dist[bestx_dist_c[di,si]]) ** 3 + np.square(0.1 * tRs_dist[pi])) / Ns[ci*nD+di,si])\n",
    "                # Calculate the likelihood of observing that RT\n",
    "                lrt_dist_c[pi,ci,di,si] = 1 / (sdrt_dist_c[pi,ci,di,si] * np.sqrt(2 * np.pi)) * \\\n",
    "                                    np.e ** (-1/2 * np.square((ert_dist_c[pi,ci,di,si] - mRTs[ci*nD+di,si]) / \\\n",
    "                                                              sdrt_dist_c[pi,ci,di,si]))\n",
    "\n",
    "# Find the set of best x values for all coherence at each distance and vice versa.\n",
    "# Then calculate the total log-likelihood for each parameter combination\n",
    "\n",
    "ll_coh_d = np.zeros((nPar, nD-1, nSub))\n",
    "ll_dist_c = np.zeros((nPar, nC-1, nSub))\n",
    "\n",
    "for si in range(nSub):\n",
    "    for pi in range(nPar):\n",
    "        # At each A-k-tR combination, find the index of x value \n",
    "        # that maximizes likelihood for each CD combination\n",
    "        for di in range(nD-1):\n",
    "            for ci in range(nC):\n",
    "                ll_coh_d[pi,di,si] += np.log(lpc_coh_d[pi,di,ci,si]) + \\\n",
    "                                      np.log(lrt_coh_d[pi,di,ci,si])\n",
    "\n",
    "        # At each A-k-tR combination, find the index of x value \n",
    "        # that maximizes likelihood for each CD combination\n",
    "        for ci in range(nC-1):\n",
    "            for di in range(nD):\n",
    "                ll_dist_c[pi,ci,si] += np.log(lpc_dist_c[pi,ci,di,si]) + \\\n",
    "                                       np.log(lrt_dist_c[pi,ci,di,si])\n",
    "                \n",
    "# The next step is to maximize over k (i.e., every set of 10 nPars)\n",
    "\n",
    "for si in range(nSub):\n",
    "    for pi in range(0, nPar, nK):\n",
    "        for di in range(nD-1):\n",
    "            # Find the best k for each A-tR combination\n",
    "            bestK = np.argmax(ll_coh_d[pi:pi+nK,di,si])\n",
    "            k_coh_d[int(pi/nK),di,si] = bestK\n",
    "            # And find the likelihood at that K for each A-tR combination\n",
    "            totLL_coh_d[int(pi/nK),di,si] = ll_coh_d[pi+bestK,di,si]\n",
    "\n",
    "        for ci in range(nC-1):\n",
    "            # Find the best k for each A-tR combination\n",
    "            bestK = np.argmax(ll_dist_c[pi:pi+nK,ci,si])\n",
    "            k_dist_c[int(pi/nK),ci,si] = bestK\n",
    "            # And find the likelihood at that K for each A-tR combination\n",
    "            totLL_dist_c[int(pi/nK),ci,si] = ll_dist_c[pi+bestK,ci,si]\n",
    "        \n",
    "# Find the parameters for which total log-likelihood is maximum\n",
    "# There are some NaN values in the likelihood matrix so exclude those\n",
    "# And record the values of best fit x for each CD combination\n",
    "for si in range(nSub):\n",
    "    for di in range(nD-1):\n",
    "        ids = np.where(totLL_coh_d[:,di,si] == np.nanmax(totLL_coh_d[:,di,si]))[0]\n",
    "        if len(ids) > 1:\n",
    "            maxParId_coh_d[di,si] = ids[0]\n",
    "        else:\n",
    "            maxParId_coh_d[di,si] = ids\n",
    "        bestk_coh_d[di,si] = k_coh[k_coh_d[maxParId_coh_d[di,si],di,si]]\n",
    "\n",
    "    for ci in range(nC-1):\n",
    "        ids = np.where(totLL_dist_c[:,ci,si] == np.nanmax(totLL_dist_c[:,ci,si]))[0]\n",
    "        if len(ids) > 1:\n",
    "            maxParId_dist_c[ci,si] = ids[0]\n",
    "        else:\n",
    "            maxParId_dist_c[ci,si] = ids\n",
    "        bestk_dist_c[ci,si] = k_dist[k_dist_c[maxParId_dist_c[ci,si],ci,si]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parId_c = np.zeros((nD, nSub), dtype = np.int)\n",
    "parId_d = np.zeros((nC, nSub), dtype = np.int)\n",
    "for si in range(nSub):\n",
    "    pcFit_c = np.zeros((nC, nD))\n",
    "    pcFit_d = np.zeros((nC, nD))\n",
    "    rtFit_c = np.zeros((nC, nD))\n",
    "    rtFit_d = np.zeros((nC, nD))\n",
    "    \n",
    "    for di in range(nD-1):\n",
    "        parId_c[di,si] = maxParId_coh_d[di,si]*nK + k_coh_d[maxParId_coh_d[di,si],di,si]\n",
    "        for ci in range(nC):\n",
    "            pcFit_c[ci,di] = epc_coh_d[parId_c[di,si], di, ci, si]\n",
    "            rtFit_c[ci,di] = ert_coh_d[parId_c[di,si], di, ci, si]\n",
    "        \n",
    "    di = nD - 1\n",
    "    parId_c[di,si] = maxParId_coh_d[di,si]*nK+k_coh_d[maxParId_coh_d[di,si],di,si]\n",
    "    for ci in range(nC):\n",
    "        pcFit_c[ci,di] = epc_coh_hi_d[parId_c[di,si], bestx_coh_d[ci,si], ci, si]\n",
    "        rtFit_c[ci,di] = ert_coh_hi_d[parId_c[di,si], bestx_coh_d[ci,si], ci, si]\n",
    "        \n",
    "    for ci in range(nC-1):\n",
    "        parId_d[ci,si] = maxParId_dist_c[ci,si]*nK+k_dist_c[maxParId_dist_c[ci,si],ci,si]\n",
    "        for di in range(nD):\n",
    "            pcFit_d[ci,di] = epc_dist_c[parId_d[ci,si], ci, di, si]\n",
    "            rtFit_d[ci,di] = ert_dist_c[parId_d[ci,si], ci, di, si]\n",
    "        \n",
    "    ci = nC - 1\n",
    "    parId_d[ci,si] = maxParId_dist_c[ci,si]*nK+k_dist_c[maxParId_dist_c[ci,si],ci,si]\n",
    "    for di in range(nD):\n",
    "        pcFit_d[ci,di] = epc_dist_hi_c[parId_d[ci,si], bestx_dist_c[di,si], di, si]\n",
    "        rtFit_d[ci,di] = ert_dist_hi_c[parId_d[ci,si], bestx_dist_c[di,si], di, si]\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.subplot(231)\n",
    "    plt.plot(pCs[:,si].reshape((nC,nD)))\n",
    "    plt.subplot(232)\n",
    "    plt.plot(pcFit_c)\n",
    "    plt.subplot(233)\n",
    "    plt.plot(pcFit_d)\n",
    "    \n",
    "    plt.subplot(234)\n",
    "    plt.plot(mRTs[:,si].reshape((nC,nD)))\n",
    "    plt.subplot(235)\n",
    "    plt.plot(rtFit_c)\n",
    "    plt.subplot(236)\n",
    "    plt.plot(rtFit_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parId_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parId_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(As_coh[parId_c].round(decimals=2))\n",
    "print(As_dist[parId_d].round(decimals=2))\n",
    "print(tRs_coh[parId_c].round(decimals=2))\n",
    "print(tRs_dist[parId_d].round(decimals=2))\n",
    "print(ks_coh[parId_c].round(decimals=3))\n",
    "print(ks_dist[parId_d].round(decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sumLL_c = np.zeros((40, nSub))\n",
    "sumLL_d = np.zeros((40, nSub))\n",
    "for si in range(nSub):\n",
    "    temp_c = 0\n",
    "    temp_d = 0\n",
    "    for di in range(nD):\n",
    "        temp_c += np.sum(totLL_coh_d[maxParId_coh_d[di,si],di,si]) \n",
    "    for ci in range(nC):\n",
    "        temp_d += np.sum(totLL_dist_c[maxParId_dist_c[ci,si],ci,si])\n",
    "    sumLL_c[0,si] = temp_c\n",
    "    sumLL_d[0,si] = temp_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sumLL_c[0,:].round(decimals=2))\n",
    "print(sumLL_d[0,:].round(decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run 2 of the model\n",
    "\n",
    "minA_coh = np.zeros((nD, nSub))\n",
    "maxA_coh = np.zeros((nD, nSub))\n",
    "mink_coh = np.zeros((nD, nSub))\n",
    "maxk_coh = np.zeros((nD, nSub))\n",
    "mintR_coh = np.zeros((nD, nSub))\n",
    "maxtR_coh = np.zeros((nD, nSub))\n",
    "\n",
    "minA_dist = np.zeros((nC, nSub))\n",
    "maxA_dist = np.zeros((nC, nSub))\n",
    "mink_dist = np.zeros((nC, nSub))\n",
    "maxk_dist = np.zeros((nC, nSub))\n",
    "mintR_dist = np.zeros((nC, nSub))\n",
    "maxtR_dist = np.zeros((nC, nSub))\n",
    "\n",
    "nd = 3 # Number of deltas before and after best fit value\n",
    "\n",
    "# Set up A, k and tR parameters for the next round of simulations\n",
    "# Use the bestx values from the first run, don't fit for x again\n",
    "\n",
    "# First set the range of all variables. \n",
    "# minVar = bestValue - dVar*nd : bestValue + dVar*nd\n",
    "# If the new minimum is <= 0, then set it to the old minimum.\n",
    "minA_coh = As_coh[parId_c] - nd * round(dA_coh, ndigits=3)\n",
    "maxA_coh = As_coh[parId_c] + nd * round(dA_coh, ndigits=3)\n",
    "\n",
    "mink_coh = ks_coh[parId_c] - nd * round(dk_coh, ndigits=3)\n",
    "maxk_coh = ks_coh[parId_c] + nd * round(dk_coh, ndigits=3)\n",
    "\n",
    "mintR_coh = tRs_coh[parId_c] - nd * round(dtR_coh, ndigits=3)\n",
    "maxtR_coh = tRs_coh[parId_c] + nd * round(dtR_coh, ndigits=3)\n",
    "\n",
    "minA_dist = As_dist[parId_d] - nd * round(dA_dist, ndigits=3)\n",
    "maxA_dist = As_dist[parId_d] + nd * round(dA_dist, ndigits=3)\n",
    "\n",
    "mink_dist = ks_dist[parId_d] - nd * round(dk_dist, ndigits=3)\n",
    "maxk_dist = ks_dist[parId_d] + nd * round(dk_dist, ndigits=3)\n",
    "\n",
    "mintR_dist = tRs_dist[parId_d] - nd * round(dtR_dist, ndigits=3)\n",
    "maxtR_dist = tRs_dist[parId_d] + nd * round(dtR_dist, ndigits=3)\n",
    "\n",
    "for si in range(nSub):\n",
    "    minA_coh[minA_coh[:,si] < Amin,si] = Amin\n",
    "    mink_coh[mink_coh[:,si] < kmin,si] = kmin\n",
    "    mintR_coh[mintR_coh[:,si] < tRmin,si] = tRmin\n",
    "\n",
    "    minA_dist[minA_dist[:,si] < Amin,si] = Amin\n",
    "    mink_dist[mink_dist[:,si] < kmin,si] = kmin\n",
    "    mintR_dist[mintR_dist[:,si] < tRmin,si] = tRmin\n",
    "\n",
    "# Set up the parameter meshgrid\n",
    "nStep = 9 # Number of values tested, per parameter\n",
    "\n",
    "A_coh = np.zeros((nStep, nD, nSub))\n",
    "dA_coh = np.zeros((nD, nSub))\n",
    "k_coh = np.zeros((nStep, nD, nSub))\n",
    "dk_coh = np.zeros((nD, nSub))\n",
    "tR_coh = np.zeros((nStep, nD, nSub))\n",
    "dtR_coh = np.zeros((nD, nSub))\n",
    "\n",
    "A_dist = np.zeros((nStep, nC, nSub))\n",
    "dA_dist = np.zeros((nC, nSub))\n",
    "k_dist = np.zeros((nStep, nC, nSub))\n",
    "dk_dist = np.zeros((nC, nSub))\n",
    "tR_dist = np.zeros((nStep, nC, nSub))\n",
    "dtR_dist = np.zeros((nC, nSub))\n",
    "\n",
    "# This is the overall number of permutations of A, k and tR being performed\n",
    "nPar = nStep ** 3\n",
    "\n",
    "As_coh = np.zeros((nPar, nD, nSub))\n",
    "ks_coh = np.zeros((nPar, nD, nSub))\n",
    "tRs_coh = np.zeros((nPar, nD, nSub))\n",
    "\n",
    "As_dist = np.zeros((nPar, nC, nSub))\n",
    "ks_dist = np.zeros((nPar, nC, nSub))\n",
    "tRs_dist = np.zeros((nPar, nC, nSub))\n",
    "\n",
    "for si in range(nSub):\n",
    "    for di in range(nD):\n",
    "        A_coh[:,di,si], dA_coh[di,si] = np.linspace(minA_coh[di,si], maxA_coh[di,si], nStep, retstep=True)\n",
    "        k_coh[:,di,si], dk_coh[di,si] = np.linspace(mink_coh[di,si], maxk_coh[di,si], nStep, retstep=True)\n",
    "        tR_coh[:,di,si], dtR_coh[di,si] = np.linspace(mintR_coh[di,si], maxtR_coh[di,si], nStep, retstep=True)\n",
    "\n",
    "        tempAs, temptRs, tempks = np.meshgrid(A_coh[:,di,si], tR_coh[:,di,si], k_coh[:,di,si])\n",
    "        As_coh[:,di,si] = tempAs.flatten()\n",
    "        ks_coh[:,di,si] = tempks.flatten()\n",
    "        tRs_coh[:,di,si] = temptRs.flatten()\n",
    "\n",
    "    for ci in range(nC):\n",
    "        A_dist[:,ci,si], dA_dist[ci,si] = np.linspace(minA_dist[ci,si], maxA_dist[ci,si], nStep, retstep=True)\n",
    "        k_dist[:,ci,si], dk_dist[ci,si] = np.linspace(mink_dist[ci,si], maxk_dist[ci,si], nStep, retstep=True)\n",
    "        tR_dist[:,ci,si], dtR_dist[ci,si] = np.linspace(mintR_dist[ci,si], maxtR_dist[ci,si], nStep, retstep=True)\n",
    "\n",
    "        tempAs, temptRs, tempks = np.meshgrid(A_dist[:,ci,si], tR_dist[:,ci,si], k_dist[:,ci,si])\n",
    "        As_dist[:,ci,si] = tempAs.flatten()\n",
    "        ks_dist[:,ci,si] = tempks.flatten()\n",
    "        tRs_dist[:,ci,si] = temptRs.flatten()\n",
    "    \n",
    "# Initialize arrays that hold predicted accuracies and RTs\n",
    "epc_coh_d = np.ones((nPar, nD, nC, nSub)) * -9\n",
    "ert_coh_d = np.ones((nPar, nD, nC, nSub)) * -9\n",
    "sdrt_coh_d = np.ones((nPar, nD, nC, nSub)) * -9\n",
    "epc_dist_c = np.ones((nPar, nC, nD, nSub)) * -9\n",
    "ert_dist_c = np.ones((nPar, nC, nD, nSub)) * -9\n",
    "sdrt_dist_c = np.ones((nPar, nC, nD, nSub)) * -9\n",
    "\n",
    "## Initialize the array that holds the\n",
    "# individual likelihood values\n",
    "lpc_coh_d = np.zeros((nPar, nD, nC, nSub))\n",
    "lrt_coh_d = np.zeros((nPar, nD, nC, nSub))\n",
    "lpc_dist_c = np.zeros((nPar, nC, nD, nSub))\n",
    "lrt_dist_c = np.zeros((nPar, nC, nD, nSub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Now find the set of A, tR and k for \n",
    "# - All coherences at all but high distance, and\n",
    "# - All distances at all but high coherence\n",
    "\n",
    "for pi in range(nPar):\n",
    "    for si in range(nSub):\n",
    "        for di in range(nD):\n",
    "            # Calculate expected accuracy and RT for all coherences at each distance \n",
    "            epc_coh_d[pi,di,:,si] = 1 / (1 + np.exp(-2 * As_coh[pi,di,si] * ks_coh[pi,di,si] * \\\n",
    "                                                    abs(x_coh[bestx_coh_d[:,si]])))\n",
    "            ert_coh_d[pi,di,:,si] = As_coh[pi,di,si] / (ks_coh[pi,di,si] * x_coh[bestx_coh_d[:,si]]) * \\\n",
    "                                    np.tanh(As_coh[pi,di,si] * ks_coh[pi,di,si] * x_coh[bestx_coh_d[:,si]]) + \\\n",
    "                                    tRs_coh[pi,di,si]\n",
    "\n",
    "            for ci in range(nC):\n",
    "                # Calculate likelihood of accuracy for all coherences at each distance\n",
    "                lpc_coh_d[pi,di,ci,si] = fact(Ns[ci*nD+di,si]) / (fact(Rs[ci*nD+di,si]) * \\\n",
    "                                                                    fact(Ns[ci*nD+di,si]-Rs[ci*nD+di,si])) \\\n",
    "                                    * (epc_coh_d[pi,di,ci,si] ** Rs[ci*nD+di,si]) * \\\n",
    "                                    ((1 - epc_coh_d[pi,di,ci,si]) ** (Ns[ci*nD+di,si] - Rs[ci*nD+di,si]))\n",
    "\n",
    "                \n",
    "                # Calculate SD of mean RT \n",
    "                sdrt_coh_d[pi,di,ci,si] = np.sqrt(((As_coh[pi,di,si] * np.tanh(As_coh[pi,di,si] * ks_coh[pi,di,si] * \\\n",
    "                                                     x_coh[bestx_coh_d[ci,si]]) - As_coh[pi,di,si] * \\\n",
    "                         ks_coh[pi,di,si] * x_coh[bestx_coh_d[ci,si]] * \\\n",
    "                        (1/np.cosh(np.square(As_coh[pi,di,si] * ks_coh[pi,di,si] * x_coh[bestx_coh_d[ci,si]])))) / \\\n",
    "                        (ks_coh[pi,di,si] * x_coh[bestx_coh_d[ci,si]]) ** 3 + \\\n",
    "                                                   np.square(0.1 * tRs_coh[pi,di,si])) / Ns[ci*nD+di,si])\n",
    "                # Calculate likelihood of mean RT for all coherences at each distance\n",
    "                lrt_coh_d[pi,di,ci,si] = 1 / (sdrt_coh_d[pi,di,ci,si] * np.sqrt(2 * np.pi)) * \\\n",
    "                                    np.e ** (-1/2 * np.square((ert_coh_d[pi,di,ci,si] - mRTs[ci*nD+di,si]) / \\\n",
    "                                                              sdrt_coh_d[pi,di,ci,si]))\n",
    "\n",
    "        for ci in range(nC):\n",
    "            # Calculate expected accuracy and RT for all distances at each coherence\n",
    "            epc_dist_c[pi,ci,:,si] = 1 / (1 + np.exp(-2 * As_dist[pi,ci,si] * ks_dist[pi,ci,si] * \\\n",
    "                                                     abs(x_dist[bestx_dist_c[:,si]])))\n",
    "            ert_dist_c[pi,ci,:,si] = As_dist[pi,ci,si] / (ks_dist[pi,ci,si] * x_dist[bestx_dist_c[:,si]]) * \\\n",
    "                                    np.tanh(As_dist[pi,ci,si] * ks_dist[pi,ci,si] * x_dist[bestx_dist_c[:,si]]) + \\\n",
    "                                    tRs_dist[pi,ci,si]\n",
    "\n",
    "            for di in range(nD):\n",
    "                # Calculate likelihood of accuracy for all distances at each coherence\n",
    "                lpc_dist_c[pi,ci,di,si] = fact(Ns[ci*nD+di,si]) / (fact(Rs[ci*nD+di,si]) * \\\n",
    "                                                                    fact(Ns[ci*nD+di,si]-Rs[ci*nD+di,si])) \\\n",
    "                                    * (epc_dist_c[pi,ci,di,si] ** Rs[ci*nD+di,si]) * \\\n",
    "                                    ((1 - epc_dist_c[pi,ci,di,si]) ** (Ns[ci*nD+di,si] - Rs[ci*nD+di,si]))\n",
    "\n",
    "                \n",
    "                # Calculate SD of mean RT \n",
    "                sdrt_dist_c[pi,ci,di,si] = np.sqrt(((As_dist[pi,ci,si] * np.tanh(As_dist[pi,ci,si] * ks_dist[pi,ci,si] * \\\n",
    "                                                            x_dist[bestx_dist_c[di,si]]) - \\\n",
    "                        As_dist[pi,ci,si] * ks_dist[pi,ci,si] * x_dist[bestx_dist_c[di,si]] * \\\n",
    "                        (1/np.cosh(np.square(As_dist[pi,ci,si] * ks_dist[pi,ci,si] * x_dist[bestx_dist_c[di,si]])))) / \\\n",
    "                        (ks_dist[pi,ci,si] * x_dist[bestx_dist_c[di,si]]) ** 3 + \\\n",
    "                                                   np.square(0.1 * tRs_dist[pi,ci,si])) / Ns[ci*nD+di,si])\n",
    "                # Calculate likelihood of mean RT for all distances at each coherence\n",
    "                lrt_dist_c[pi,ci,di,si] = 1 / (sdrt_dist_c[pi,ci,di,si] * np.sqrt(2 * np.pi)) * \\\n",
    "                                    np.e ** (-1/2 * np.square((ert_dist_c[pi,ci,di,si] - mRTs[ci*nD+di,si]) / \\\n",
    "                                                              sdrt_dist_c[pi,ci,di,si]))\n",
    "                \n",
    "                \n",
    "# Calculate the total log-likelihood for:\n",
    "# all coherences at each distance\n",
    "# all distances at each coherence\n",
    "ll_coh_d = np.zeros((nPar, nD, nSub))\n",
    "ll_dist_c = np.zeros((nPar, nC, nSub))\n",
    "\n",
    "for si in range(nSub):\n",
    "    for pi in range(nPar):\n",
    "        for di in range(nD):\n",
    "            ll_coh_d[pi,di,si] += np.sum(np.log(lpc_coh_d[pi,di,:,si])) + \\\n",
    "                                  np.sum(np.log(lrt_coh_d[pi,di,:,si]))\n",
    "                    \n",
    "        for ci in range(nC):\n",
    "            ll_dist_c[pi,ci,si] += np.sum(np.log(lpc_dist_c[pi,ci,:,si])) + \\\n",
    "                                   np.sum(np.log(lrt_dist_c[pi,ci,:,si]))        \n",
    "        \n",
    "# For each A-tR combination, calculate best k value\n",
    "k_coh_d = np.ones((int(nPar/nStep), nD, nSub), dtype = int) * -9\n",
    "k_dist_c = np.ones((int(nPar/nStep), nC, nSub), dtype = int) * -9\n",
    "\n",
    "totLL_coh_d = np.zeros((int(nPar/nStep), nD, nSub))\n",
    "totLL_dist_c = np.zeros((int(nPar/nStep), nC, nSub))\n",
    "\n",
    "for si in range(nSub):\n",
    "    for pi in range(0, nPar, nStep):\n",
    "        for di in range(nD):\n",
    "            # Find the best k for each A-tR combination\n",
    "            bestK = np.argmax(ll_coh_d[pi:pi+nStep,di,si])\n",
    "            k_coh_d[int(pi/nStep),di,si] = bestK\n",
    "            # And find the likelihood at that K for each A-tR combination\n",
    "            totLL_coh_d[int(pi/nStep),di,si] = ll_coh_d[pi+bestK,di,si]\n",
    "            \n",
    "        for ci in range(nC):\n",
    "            # Find the best k for each A-tR combination\n",
    "            bestK = np.argmax(ll_dist_c[pi:pi+nStep,ci,si])\n",
    "            k_dist_c[int(pi/nStep),ci,si] = bestK\n",
    "            # And find the likelihood at that K for each A-tR combination\n",
    "            totLL_dist_c[int(pi/nStep),ci,si] = ll_dist_c[pi+bestK,ci,si]\n",
    "\n",
    "# Find the parameters for which total log-likelihood is maximum\n",
    "# There are some NaN values in the likelihood matrix so exclude those\n",
    "maxParId_coh_d = np.zeros((nD, nSub), dtype = np.int)\n",
    "maxParId_dist_c = np.zeros((nC, nSub), dtype = np.int)\n",
    "\n",
    "# Record the values of best fit x for each CD combination\n",
    "bestk_coh_d = np.zeros((nD, nSub))\n",
    "bestk_dist_c = np.zeros((nC, nSub))\n",
    "for si in range(nSub):\n",
    "    for di in range(nD):\n",
    "        ids = np.where(totLL_coh_d[:,di,si] == np.nanmax(totLL_coh_d[:,di,si]))[0]\n",
    "        if len(ids) > 1:\n",
    "            maxParId_coh_d[di,si] = ids[0]\n",
    "        else:\n",
    "            maxParId_coh_d[di,si] = ids\n",
    "        bestk_coh_d[di,si] = k_coh[k_coh_d[maxParId_coh_d[di,si],di,si],di,si]\n",
    "        \n",
    "    for ci in range(nC):\n",
    "        ids = np.where(totLL_dist_c[:,ci,si] == np.nanmax(totLL_dist_c[:,ci,si]))[0]\n",
    "        if len(ids) > 1:\n",
    "            maxParId_dist_c[ci,si] = ids[0]\n",
    "        else:\n",
    "            maxParId_dist_c[ci,si] = ids\n",
    "        bestk_dist_c[ci,si] = k_dist[k_dist_c[maxParId_dist_c[ci,si],ci,si],ci,si]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parId_c = np.zeros((nD, nSub), dtype = np.int)\n",
    "parId_d = np.zeros((nC, nSub), dtype = np.int)\n",
    "for si in range(nSub):\n",
    "    pcFit_c = np.zeros((nC, nD))\n",
    "    pcFit_d = np.zeros((nC, nD))\n",
    "    rtFit_c = np.zeros((nC, nD))\n",
    "    rtFit_d = np.zeros((nC, nD))\n",
    "    \n",
    "    for di in range(nD):\n",
    "        parId_c[di,si] = (maxParId_coh_d[di,si]*nStep+k_coh_d[maxParId_coh_d[di,si],di,si])\n",
    "        pcFit_c[:,di] = epc_coh_d[parId_c[di,si], di, :, si]\n",
    "        rtFit_c[:,di] = ert_coh_d[parId_c[di,si], di, :, si]\n",
    "        \n",
    "    for ci in range(nC):\n",
    "        parId_d[ci,si] = (maxParId_dist_c[ci,si]*nStep+k_dist_c[maxParId_dist_c[ci,si],ci,si])\n",
    "        pcFit_d[ci,:] = epc_dist_c[parId_d[ci,si], ci, :, si]\n",
    "        rtFit_d[ci,:] = ert_dist_c[parId_d[ci,si], ci, :, si]\n",
    "        \n",
    "    ymin = 0.3\n",
    "    ymax = 1.1\n",
    "    plt.figure()\n",
    "    plt.subplot(231)\n",
    "    plt.plot(pCs[:,si].reshape((nC,nD)), '-o')\n",
    "    plt.ylim((ymin,ymax))\n",
    "    plt.subplot(232)\n",
    "    plt.plot(pcFit_c, '-o')\n",
    "    plt.ylim((ymin,ymax))\n",
    "    plt.subplot(233)\n",
    "    plt.plot(pcFit_d, '-o')\n",
    "    plt.ylim((ymin,ymax))\n",
    "    \n",
    "    ymin = 0.6\n",
    "    ymax = 3\n",
    "    plt.subplot(234)\n",
    "    plt.plot(mRTs[:,si].reshape((nC,nD)), '-o')\n",
    "    plt.ylim((ymin,ymax))\n",
    "    plt.subplot(235)\n",
    "    plt.plot(rtFit_c, '-o')\n",
    "    plt.ylim((ymin,ymax))\n",
    "    plt.subplot(236)\n",
    "    plt.plot(rtFit_d, '-o')\n",
    "    plt.ylim((ymin,ymax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for si in range(nSub):\n",
    "    temp_c = 0\n",
    "    temp_d = 0\n",
    "    for di in range(nD):\n",
    "        temp_c += np.sum(totLL_coh_d[maxParId_coh_d[di,si],di,si]) \n",
    "    for ci in range(nC):\n",
    "        temp_d += np.sum(totLL_dist_c[maxParId_dist_c[ci,si],ci,si])\n",
    "    sumLL_c[1,si] = temp_c\n",
    "    sumLL_d[1,si] = temp_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sumLL_c[0:2,:].round(decimals=2))\n",
    "print(sumLL_d[0:2,:].round(decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the values of the parameters and the likelihoods after the second run\n",
    "pars_c = np.zeros((3, nD, nSub))\n",
    "lls_c = np.zeros(nSub)\n",
    "pars_d = np.zeros((3, nC, nSub))\n",
    "lls_d = np.zeros(nSub)\n",
    "\n",
    "for si in range(nSub):\n",
    "    pars_c[0,:,si] = np.diag(As_coh[parId_c[:,si],:,si])\n",
    "    pars_c[1,:,si] = np.diag(ks_coh[parId_c[:,si],:,si])\n",
    "    pars_c[2,:,si] = np.diag(tRs_coh[parId_c[:,si],:,si])\n",
    "    lls_c[si] = sumLL_c[1,si]\n",
    "    \n",
    "    pars_d[0,:,si] = np.diag(As_dist[parId_d[:,si],:,si])\n",
    "    pars_d[1,:,si] = np.diag(ks_dist[parId_d[:,si],:,si])\n",
    "    pars_d[2,:,si] = np.diag(tRs_dist[parId_d[:,si],:,si])\n",
    "    lls_d[si] = sumLL_d[1,si]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run the simulation until it converges on a maximum likelihood, for parameteric coherences at each distance\n",
    "\n",
    "run_c = np.ones(nSub, dtype = np.int) * 2\n",
    "# Number of values generated per parameter, for each simulation run\n",
    "nStep = 9\n",
    "# Overall number of permutations of A, k and tR being performed\n",
    "nPar = nStep ** 3\n",
    "\n",
    "# Now we are going to maximize the likelihood for each subject separately.\n",
    "for si in range(nSub):\n",
    "    # Initialize the minimum and maximum values of the parameters\n",
    "    minA = np.zeros(nD)\n",
    "    maxA = np.zeros(nD)\n",
    "    mink = np.zeros(nD)\n",
    "    maxk = np.zeros(nD)\n",
    "    mintR = np.zeros(nD)\n",
    "    maxtR = np.zeros(nD)\n",
    "\n",
    "    minA = np.diag(As_coh[parId_c[:,si],:,si].round(decimals=3)) - nd * dA_coh[:,si].round(decimals=3)\n",
    "    maxA = np.diag(As_coh[parId_c[:,si],:,si].round(decimals=3)) + nd * dA_coh[:,si].round(decimals=3)\n",
    "\n",
    "    mink = np.diag(ks_coh[parId_c[:,si],:,si].round(decimals=3)) - nd * dk_coh[:,si].round(decimals=3)\n",
    "    maxk = np.diag(ks_coh[parId_c[:,si],:,si].round(decimals=3)) + nd * dk_coh[:,si].round(decimals=3)\n",
    "\n",
    "    mintR = np.diag(tRs_coh[parId_c[:,si],:,si].round(decimals=3)) - nd * dtR_coh[:,si].round(decimals=3)\n",
    "    maxtR = np.diag(tRs_coh[parId_c[:,si],:,si].round(decimals=3)) + nd * dtR_coh[:,si].round(decimals=3)\n",
    "\n",
    "    # If any parameter is less than the minimum allowed value for that parameter, \n",
    "    # set it to the minimum allowed value\n",
    "    minA[minA < Amin] = Amin\n",
    "    mink[mink < kmin] = kmin\n",
    "    mintR[mintR < tRmin] = tRmin\n",
    "\n",
    "    A_run = []\n",
    "    k_run = []\n",
    "    tR_run = []\n",
    "    \n",
    "    # This variable keeps track of whether the simulation should continue or not\n",
    "    simStop = 0\n",
    "\n",
    "    while simStop == 0:\n",
    "        if (maxA - minA).all() > 0.01 and (maxk - mink).all() > 0.001 and (maxtR - mintR).all() > 0.01:\n",
    "            # Set up the parameter meshgrid\n",
    "            A = np.zeros((nStep, nD))\n",
    "            dA = np.zeros(nD)\n",
    "            k = np.zeros((nStep, nD))\n",
    "            dk = np.zeros(nD)\n",
    "            tR = np.zeros((nStep, nD))\n",
    "            dtR = np.zeros(nD)\n",
    "            \n",
    "            As = np.zeros((nPar, nD))\n",
    "            ks = np.zeros((nPar, nD))\n",
    "            tRs = np.zeros((nPar, nD))\n",
    "\n",
    "            for di in range(nD):\n",
    "                A[:,di], dA[di] = np.linspace(minA[di], maxA[di], nStep, retstep=True)\n",
    "                k[:,di], dk[di] = np.linspace(mink[di], maxk[di], nStep, retstep=True)\n",
    "                tR[:,di], dtR[di] = np.linspace(mintR[di], maxtR[di], nStep, retstep=True)\n",
    "\n",
    "                tempAs, temptRs, tempks = np.meshgrid(A[:,di], tR[:,di], k[:,di])\n",
    "                As[:,di] = tempAs.flatten()\n",
    "                ks[:,di] = tempks.flatten()\n",
    "                tRs[:,di] = temptRs.flatten()\n",
    "\n",
    "            # Initialize arrays that hold predicted accuracies and RTs\n",
    "            epc = np.ones((nPar, nD, nC)) * -9\n",
    "            ert = np.ones((nPar, nD, nC)) * -9\n",
    "            sdrt = np.ones((nPar, nD, nC)) * -9\n",
    "\n",
    "            ## Initialize the array that holds the\n",
    "            # individual likelihood values\n",
    "            lpc = np.zeros((nPar, nD, nC))\n",
    "            lrt = np.zeros((nPar, nD, nC))\n",
    "\n",
    "            ## Now find the set of xs for \n",
    "            # - All coherences at high distance, and\n",
    "            # - All distances at high coherence\n",
    "\n",
    "            # Save the total log-likelihood for all coherences at each distance\n",
    "            ll = np.zeros((nPar, nD))\n",
    "            for pi in range(nPar):\n",
    "                for di in range(nD):\n",
    "                    # Calculate expected accuracy and RT for all coherences at each distance \n",
    "                    epc[pi,di,:] = 1 / (1 + np.exp(-2 * As[pi,di] * ks[pi,di] * abs(x_coh[bestx_coh_d[:,si]])))\n",
    "                    ert[pi,di,:] = As[pi,di] / (ks[pi,di] * x_coh[bestx_coh_d[:,si]]) * \\\n",
    "                                            np.tanh(As[pi,di] * ks[pi,di] * x_coh[bestx_coh_d[:,si]]) + tRs[pi,di]\n",
    "\n",
    "                    for ci in range(nC):\n",
    "                        # Calculate likelihood of accuracy for all coherences at each distance\n",
    "                        lpc[pi,di,ci] = fact(Ns[ci*nD+di,si]) / (fact(Rs[ci*nD+di,si]) * fact(Ns[ci*nD+di,si]-Rs[ci*nD+di,si])) \\\n",
    "                                            * (epc[pi,di,ci] ** Rs[ci*nD+di,si]) * \\\n",
    "                                            ((1 - epc[pi,di,ci]) ** (Ns[ci*nD+di,si] - Rs[ci*nD+di,si]))\n",
    "\n",
    "\n",
    "                        # Calculate SD of mean RT \n",
    "                        sdrt[pi,di,ci] = np.sqrt(((As[pi,di] * np.tanh(As[pi,di] * ks[pi,di] * \\\n",
    "                                        x_coh[bestx_coh_d[ci,si]]) - As[pi,di] * ks[pi,di] * x_coh[bestx_coh_d[ci,si]] * \\\n",
    "                                (1/np.cosh(np.square(As[pi,di] * ks[pi,di] * x_coh[bestx_coh_d[ci,si]])))) / \\\n",
    "                                (ks[pi,di] * x_coh[bestx_coh_d[ci,si]]) ** 3 + np.square(0.1 * tRs[pi,di])) / Ns[ci*nD+di,si])\n",
    "                        # Calculate likelihood of mean RT for all coherences at each distance\n",
    "                        lrt[pi,di,ci] = 1 / (sdrt[pi,di,ci] * np.sqrt(2 * np.pi)) * \\\n",
    "                                            np.e ** (-1/2 * np.square((ert[pi,di,ci] - mRTs[ci*nD+di,si]) / sdrt[pi,di,ci]))\n",
    "\n",
    "                    # Calculate the total log-likelihood for all coherences at each distance\n",
    "                    ll[pi,di] += np.sum(np.log(lpc[pi,di,:])) + np.sum(np.log(lrt[pi,di,:]))\n",
    "\n",
    "            # For each A-tR combination, calculate best k value\n",
    "            k_id = np.ones((int(nPar/nStep), nD), dtype = int) * -9\n",
    "            totLL = np.zeros((int(nPar/nStep), nD))\n",
    "\n",
    "            for pi in range(0, nPar, nStep):\n",
    "                for di in range(nD):\n",
    "                    # Find the best k for each A-tR combination\n",
    "                    bestK = np.argmax(ll[pi:pi+nStep,di])\n",
    "                    k_id[int(pi/nStep),di] = bestK\n",
    "                    # And find the likelihood at that K for each A-tR combination\n",
    "                    totLL[int(pi/nStep),di] = ll[pi+bestK,di]\n",
    "\n",
    "            # Find the parameters for which total log-likelihood is maximum\n",
    "            # There are some NaN values in the likelihood matrix so exclude those\n",
    "            maxParId = np.zeros(nD, dtype = np.int)\n",
    "\n",
    "            # Record the values of best fit x for each CD combination\n",
    "            bestk = np.zeros(nD)\n",
    "            for di in range(nD):\n",
    "                ids = np.where(totLL[:,di] == np.nanmax(totLL[:,di]))[0]\n",
    "                if len(ids) == 0:\n",
    "                    simStop = 1\n",
    "                elif len(ids) > 1:\n",
    "                    maxParId[di] = ids[0]\n",
    "                else:\n",
    "                    maxParId[di] = ids\n",
    "                \n",
    "            # Calculate total maximum loglikelihoods\n",
    "            temp = 0\n",
    "            for di in range(nD):\n",
    "                temp += np.sum(totLL[maxParId[di],di]) \n",
    "\n",
    "            # Check to see if the simulation should continue for another run\n",
    "            if simStop == 1 or \\\n",
    "            temp == sumLL_c[run_c[si]-2,si] or \\\n",
    "            (temp > sumLL_c[run_c[si]-1,si] and abs(sumLL_c[run_c[si]-1,si] - temp) <= 0.5) or \\\n",
    "            (temp < sumLL_c[run_c[si]-1,si] and abs(temp - sumLL_c[run_c[si]-1,si]) >= 15):\n",
    "                simStop = 1\n",
    "            else:\n",
    "                sumLL_c[run_c[si],si] = temp\n",
    "                run_c[si] += 1\n",
    "                \n",
    "                parId = maxParId * nStep + np.diag(k_id[maxParId,:])\n",
    "                A_run.append(np.diag(As[parId,:]))\n",
    "                k_run.append(np.diag(ks[parId,:]))\n",
    "                tR_run.append(np.diag(tRs[parId,:]))\n",
    "\n",
    "                # Re-initialize the minimum and maximum values of parameters for the next run\n",
    "                minA = np.diag(As[parId,:].round(decimals=3)) - nd * dA.round(decimals=3)\n",
    "                maxA = np.diag(As[parId,:].round(decimals=3)) + nd * dA.round(decimals=3)\n",
    "\n",
    "                mink = np.diag(ks[parId,:].round(decimals=3)) - nd * dk.round(decimals=3)\n",
    "                maxk = np.diag(ks[parId,:].round(decimals=3)) + nd * dk.round(decimals=3)\n",
    "\n",
    "                mintR = np.diag(tRs[parId,:].round(decimals=3)) - nd * dtR.round(decimals=3)\n",
    "                maxtR = np.diag(tRs[parId,:].round(decimals=3)) + nd * dtR.round(decimals=3)\n",
    "\n",
    "                minA[minA < Amin] = Amin\n",
    "                mink[mink < kmin] = kmin\n",
    "                mintR[mintR < tRmin] = tRmin\n",
    "        else:\n",
    "            simStop = 1\n",
    "    \n",
    "    # Save the parameter values from the final simulation run\n",
    "    if run_c[si] > 2:\n",
    "        pars_c[0,:,si] = A_run[-1]\n",
    "        pars_c[1,:,si] = k_run[-1]\n",
    "        pars_c[2,:,si] = tR_run[-1]\n",
    "        lls_c[si] = sumLL_c[run_c[si]-1,si]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(lls_c.round(decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(lls_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run the simulation until it converges on a maximum likelihood, for parameteric distances at each coherence\n",
    "\n",
    "run_d = np.ones(nSub, dtype = np.int) * 2\n",
    "# Number of values generated per parameter, for each simulation run\n",
    "nStep = 9\n",
    "# Overall number of permutations of A, k and tR being performed\n",
    "nPar = nStep ** 3\n",
    "\n",
    "# Now we are going to maximize the likelihood for each subject separately.\n",
    "for si in range(nSub):\n",
    "    # Initialize the minimum and maximum values of the parameters\n",
    "    minA = np.zeros(nC)\n",
    "    maxA = np.zeros(nC)\n",
    "    mink = np.zeros(nC)\n",
    "    maxk = np.zeros(nC)\n",
    "    mintR = np.zeros(nC)\n",
    "    maxtR = np.zeros(nC)\n",
    "\n",
    "    minA = np.diag(As_dist[parId_d[:,si],:,si].round(decimals=3)) - nd * dA_dist[:,si].round(decimals=3)\n",
    "    maxA = np.diag(As_dist[parId_d[:,si],:,si].round(decimals=3)) + nd * dA_dist[:,si].round(decimals=3)\n",
    "\n",
    "    mink = np.diag(ks_dist[parId_d[:,si],:,si].round(decimals=3)) - nd * dk_dist[:,si].round(decimals=3)\n",
    "    maxk = np.diag(ks_dist[parId_d[:,si],:,si].round(decimals=3)) + nd * dk_dist[:,si].round(decimals=3)\n",
    "\n",
    "    mintR = np.diag(tRs_dist[parId_d[:,si],:,si].round(decimals=3)) - nd * dtR_dist[:,si].round(decimals=3)\n",
    "    maxtR = np.diag(tRs_dist[parId_d[:,si],:,si].round(decimals=3)) + nd * dtR_dist[:,si].round(decimals=3)\n",
    "\n",
    "    # If any parameter is less than the minimum allowed value for that parameter, \n",
    "    # set it to the minimum allowed value\n",
    "    minA[minA < Amin] = Amin\n",
    "    mink[mink < kmin] = kmin\n",
    "    mintR[mintR < tRmin] = tRmin\n",
    "\n",
    "    # This variable keeps track of whether the simulation should continue or not\n",
    "    simStop = 0\n",
    "\n",
    "    A_run = []\n",
    "    k_run = []\n",
    "    tR_run = []\n",
    "    \n",
    "    while simStop == 0:\n",
    "        if (maxA - minA).all() > 0.01 and (maxk - mink).all() > 0.001 and (maxtR - mintR).all() > 0.01:\n",
    "            # Set up the parameter meshgrid\n",
    "            A = np.zeros((nStep, nC))\n",
    "            dA = np.zeros(nC)\n",
    "            k = np.zeros((nStep, nC))\n",
    "            dk = np.zeros(nC)\n",
    "            tR = np.zeros((nStep, nC))\n",
    "            dtR = np.zeros(nC)\n",
    "            \n",
    "            As = np.zeros((nPar, nC))\n",
    "            ks = np.zeros((nPar, nC))\n",
    "            tRs = np.zeros((nPar, nC))\n",
    "\n",
    "            for ci in range(nC):\n",
    "                A[:,ci], dA[ci] = np.linspace(minA[ci], maxA[ci], nStep, retstep=True)\n",
    "                k[:,ci], dk[ci] = np.linspace(mink[ci], maxk[ci], nStep, retstep=True)\n",
    "                tR[:,ci], dtR[ci] = np.linspace(mintR[ci], maxtR[ci], nStep, retstep=True)\n",
    "\n",
    "                tempAs, temptRs, tempks = np.meshgrid(A[:,ci], tR[:,ci], k[:,ci])\n",
    "                As[:,ci] = tempAs.flatten()\n",
    "                ks[:,ci] = tempks.flatten()\n",
    "                tRs[:,ci] = temptRs.flatten()\n",
    "\n",
    "            # Initialize arrays that hold predicted accuracies and RTs\n",
    "            epc = np.ones((nPar, nC, nD)) * -9\n",
    "            ert = np.ones((nPar, nC, nD)) * -9\n",
    "            sdrt = np.ones((nPar, nC, nD)) * -9\n",
    "\n",
    "            ## Initialize the array that holds the\n",
    "            # individual likelihood values\n",
    "            lpc = np.zeros((nPar, nC, nD))\n",
    "            lrt = np.zeros((nPar, nC, nD))\n",
    "\n",
    "            ## Now find the set of xs for \n",
    "            # - All coherences at high distance, and\n",
    "            # - All distances at high coherence\n",
    "\n",
    "            # Save the total log-likelihood for all coherences at each distance\n",
    "            ll = np.zeros((nPar, nC))\n",
    "            for pi in range(nPar):\n",
    "                for ci in range(nC):\n",
    "                    # Calculate expected accuracy and RT for all coherences at each distance \n",
    "                    epc[pi,ci,:] = 1 / (1 + np.exp(-2 * As[pi,ci] * ks[pi,ci] * abs(x_dist[bestx_dist_c[:,si]])))\n",
    "                    ert[pi,ci,:] = As[pi,ci] / (ks[pi,ci] * x_dist[bestx_dist_c[:,si]]) * \\\n",
    "                                            np.tanh(As[pi,ci] * ks[pi,ci] * x_dist[bestx_dist_c[:,si]]) + tRs[pi,ci]\n",
    "\n",
    "                    for di in range(nD):\n",
    "                        # Calculate likelihood of accuracy for all coherences at each distance\n",
    "                        lpc[pi,ci,di] = fact(Ns[ci*nD+di,si]) / (fact(Rs[ci*nD+di,si]) * fact(Ns[ci*nD+di,si]-Rs[ci*nD+di,si])) \\\n",
    "                                            * (epc[pi,ci,di] ** Rs[ci*nD+di,si]) * \\\n",
    "                                            ((1 - epc[pi,ci,di]) ** (Ns[ci*nD+di,si] - Rs[ci*nD+di,si]))\n",
    "\n",
    "\n",
    "                        # Calculate SD of mean RT \n",
    "                        sdrt[pi,ci,di] = np.sqrt(((As[pi,ci] * np.tanh(As[pi,ci] * ks[pi,ci] * \\\n",
    "                                        x_dist[bestx_dist_c[di,si]]) - As[pi,ci] * ks[pi,ci] * x_dist[bestx_dist_c[di,si]] \\\n",
    "                                * (1/np.cosh(np.square(As[pi,ci] * ks[pi,ci] * x_dist[bestx_dist_c[di,si]])))) / \\\n",
    "                                (ks[pi,ci] * x_dist[bestx_dist_c[di,si]]) ** 3 + np.square(0.1 * tRs[pi,ci])) / \\\n",
    "                                                 Ns[ci*nD+di,si])\n",
    "                        # Calculate likelihood of mean RT for all coherences at each distance\n",
    "                        lrt[pi,ci,di] = 1 / (sdrt[pi,ci,di] * np.sqrt(2 * np.pi)) * \\\n",
    "                                            np.e ** (-1/2 * np.square((ert[pi,ci,di] - mRTs[ci*nD+di,si]) / sdrt[pi,ci,di]))\n",
    "\n",
    "                    # Calculate the total log-likelihood for all coherences at each distance\n",
    "                    ll[pi,ci] += np.sum(np.log(lpc[pi,ci,:])) + np.sum(np.log(lrt[pi,ci,:]))\n",
    "\n",
    "            # For each A-tR combination, calculate best k value\n",
    "            k_id = np.ones((int(nPar/nStep), nC), dtype = int) * -9\n",
    "            totLL = np.zeros((int(nPar/nStep), nC))\n",
    "\n",
    "            for pi in range(0, nPar, nStep):\n",
    "                for ci in range(nC):\n",
    "                    # Find the best k for each A-tR combination\n",
    "                    bestK = np.argmax(ll[pi:pi+nStep,ci])\n",
    "                    k_id[int(pi/nStep),ci] = bestK\n",
    "                    # And find the likelihood at that K for each A-tR combination\n",
    "                    totLL[int(pi/nStep),ci] = ll[pi+bestK,ci]\n",
    "\n",
    "            # Find the parameters for which total log-likelihood is maximum\n",
    "            # There are some NaN values in the likelihood matrix so exclude those\n",
    "            maxParId = np.zeros(nC, dtype = np.int)\n",
    "\n",
    "            # Record the values of best fit x for each CD combination\n",
    "            bestk = np.zeros(nC)\n",
    "            for ci in range(nC):\n",
    "                ids = np.where(totLL[:,ci] == np.nanmax(totLL[:,ci]))[0]\n",
    "                if len(ids) == 0:\n",
    "                    simStop = 1\n",
    "                elif len(ids) > 1:\n",
    "                    maxParId[ci] = ids[0]\n",
    "                else:\n",
    "                    maxParId[ci] = ids\n",
    "                \n",
    "            # Calculate total maximum loglikelihoods\n",
    "            temp = 0\n",
    "            for ci in range(nC):\n",
    "                temp += np.sum(totLL[maxParId[ci],ci]) \n",
    "\n",
    "            # Check to see if the simulation should continue for another run\n",
    "            if simStop == 1 or \\\n",
    "            temp == sumLL_d[run_d[si]-2,si] or \\\n",
    "            (temp > sumLL_d[run_d[si]-1,si] and abs(sumLL_d[run_d[si]-1,si] - temp) <= 0.5) or \\\n",
    "            (temp < sumLL_d[run_d[si]-1,si] and abs(temp - sumLL_d[run_d[si]-1,si]) >= 15):\n",
    "                simStop = 1\n",
    "            else:\n",
    "                sumLL_d[run_d[si],si] = temp\n",
    "                run_d[si] += 1\n",
    "                \n",
    "                parId = maxParId * nStep + np.diag(k_id[maxParId,:])\n",
    "                A_run.append(np.diag(As[parId,:]))\n",
    "                k_run.append(np.diag(ks[parId,:]))\n",
    "                tR_run.append(np.diag(tRs[parId,:]))\n",
    "\n",
    "                # Re-initialize the minimum and maximum values of parameters for the next run\n",
    "                minA = np.diag(As[parId,:].round(decimals=3)) - nd * dA.round(decimals=3)\n",
    "                maxA = np.diag(As[parId,:].round(decimals=3)) + nd * dA.round(decimals=3)\n",
    "\n",
    "                mink = np.diag(ks[parId,:].round(decimals=3)) - nd * dk.round(decimals=3)\n",
    "                maxk = np.diag(ks[parId,:].round(decimals=3)) + nd * dk.round(decimals=3)\n",
    "\n",
    "                mintR = np.diag(tRs[parId,:].round(decimals=3)) - nd * dtR.round(decimals=3)\n",
    "                maxtR = np.diag(tRs[parId,:].round(decimals=3)) + nd * dtR.round(decimals=3)\n",
    "\n",
    "                minA[minA < Amin] = Amin\n",
    "                mink[mink < kmin] = kmin\n",
    "                mintR[mintR < tRmin] = tRmin\n",
    "        else:\n",
    "            simStop = 1\n",
    "    \n",
    "    # Save the parameter values from the final simulation run\n",
    "    if run_d[si] > 2:\n",
    "        pars_d[0,:,si] = A_run[-1]\n",
    "        pars_d[1,:,si] = k_run[-1]\n",
    "        pars_d[2,:,si] = tR_run[-1]\n",
    "        lls_d[si] = sumLL_d[run_d[si]-1,si]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(lls_d.round(decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(lls_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pcFit_c = np.zeros((nC, nD, nSub))\n",
    "pcFit_d = np.zeros((nC, nD, nSub))\n",
    "rtFit_c = np.zeros((nC, nD, nSub))\n",
    "rtFit_d = np.zeros((nC, nD, nSub))\n",
    "    \n",
    "for si in range(nSub):\n",
    "    for di in range(nD):\n",
    "        pcFit_c[:,di,si] = 1 / (1 + np.exp(-2 * pars_c[0,di,si] * pars_c[1,di,si] * abs(x_coh[bestx_coh_d[:,si]])))\n",
    "        rtFit_c[:,di,si] = pars_c[0,di,si] / (pars_c[1,di,si] * x_coh[bestx_coh_d[:,si]]) * \\\n",
    "                        np.tanh(pars_c[0,di,si] * pars_c[1,di,si] * x_coh[bestx_coh_d[:,si]]) + \\\n",
    "                        pars_c[2,di,si]\n",
    "        \n",
    "    for ci in range(nC):\n",
    "        pcFit_d[ci,:,si] = 1 / (1 + np.exp(-2 * pars_d[0,ci,si] * pars_d[1,ci,si] * abs(x_dist[bestx_dist_c[:,si]])))\n",
    "        rtFit_d[ci,:,si] = pars_d[0,ci,si] / (pars_d[1,ci,si] * x_dist[bestx_dist_c[:,si]]) * \\\n",
    "                        np.tanh(pars_d[0,ci,si] * pars_d[1,ci,si] * x_dist[bestx_dist_c[:,si]]) + \\\n",
    "                        pars_d[2,ci,si]\n",
    "        \n",
    "    ymin = 0.3\n",
    "    ymax = 1.1\n",
    "    plt.figure()\n",
    "    plt.subplot(231)\n",
    "    plt.plot(pCs[:,si].reshape((nC,nD)),'o-')\n",
    "    plt.ylim((ymin,ymax))\n",
    "    plt.subplot(232)\n",
    "    plt.plot(pcFit_c[...,si],'o-')\n",
    "    plt.ylim((ymin,ymax))\n",
    "    plt.subplot(233)\n",
    "    plt.plot(pcFit_d[...,si],'o-')\n",
    "    plt.ylim((ymin,ymax))\n",
    "    \n",
    "    ymin = 0.6\n",
    "    ymax = 3\n",
    "    plt.subplot(234)\n",
    "    plt.plot(mRTs[:,si].reshape((nC,nD)),'o-')\n",
    "    plt.ylim((ymin,ymax))\n",
    "    plt.subplot(235)\n",
    "    plt.plot(rtFit_c[...,si],'o-')\n",
    "    plt.ylim((ymin,ymax))\n",
    "    plt.subplot(236)\n",
    "    plt.plot(rtFit_d[...,si],'o-')\n",
    "    plt.ylim((ymin,ymax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Final A values for parametric coherence at each distance\n",
    "pars_c[0,:,:].T.round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Final A values for parametric distance at each coherence\n",
    "pars_d[0,:,:].T.round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Final k values for parametric coherence at each distance\n",
    "pars_c[1,:,:].T.round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Final k values for parametric distance at each coherence\n",
    "pars_d[1,:,:].T.round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Final tR values for parametric coherence at each distance\n",
    "pars_c[2,:,:].T.round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Final tR values for parametric distance at each coherence\n",
    "pars_d[2,:,:].T.round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open a file to save model results \n",
    "# Save data from the Coherence model\n",
    "fitFile = open('CoherenceModel_3distances_v2', 'w')\n",
    "\n",
    "# Write parameter ranges to file\n",
    "fitFile.write('Final A values:\\n')\n",
    "fitFile.write(str(repr(pars_c[0,:,:].round(decimals=2))) + '\\n')\n",
    "fitFile.write('Final k values:\\n')\n",
    "fitFile.write(str(repr(pars_c[1,:,:].round(decimals=2))) + '\\n')\n",
    "fitFile.write('Final tR values:\\n')\n",
    "fitFile.write(str(repr(pars_c[2,:,:].round(decimals=2))) + '\\n')\n",
    "fitFile.write('Final log-likelihood values:\\n')\n",
    "fitFile.write(str(repr(lls_c.round(decimals=2))) + '\\n')\n",
    "\n",
    "fitFile.write('\\nFinal PC values:\\n')\n",
    "for si in range(nSub):\n",
    "    pcFit_c = np.zeros((nC, nD))\n",
    "    \n",
    "    for di in range(nD):\n",
    "        pcFit_c[:,di] = 1 / (1 + np.exp(-2 * pars_c[0,di,si] * pars_c[1,di,si] * abs(x_coh[bestx_coh_d[:,si]])))\n",
    "        \n",
    "    fitFile.write(subs[si] + ':\\n')\n",
    "    fitFile.write(str(repr(pcFit_c.round(decimals=2))) + '\\n')\n",
    "    \n",
    "fitFile.write('\\nFinal RT values:\\n')\n",
    "for si in range(nSub):\n",
    "    rtFit_c = np.zeros((nC, nD))\n",
    "    \n",
    "    for di in range(nD):\n",
    "        rtFit_c[:,di] = pars_c[0,di,si] / (pars_c[1,di,si] * x_coh[bestx_coh_d[:,si]]) * \\\n",
    "                        np.tanh(pars_c[0,di,si] * pars_c[1,di,si] * x_coh[bestx_coh_d[:,si]]) + \\\n",
    "                        pars_c[2,di,si]\n",
    "\n",
    "    fitFile.write(subs[si] + ':\\n')\n",
    "    fitFile.write(str(repr(rtFit_c.round(decimals=2))) + '\\n')\n",
    "    \n",
    "fitFile.close()\n",
    "\n",
    "# Save data from the Distance model\n",
    "fitFile = open('DistanceModel_3distances', 'w')\n",
    "\n",
    "# Write parameter ranges to file\n",
    "fitFile.write('Final A values:\\n')\n",
    "fitFile.write(str(repr(pars_d[0,:,:].round(decimals=2))) + '\\n')\n",
    "fitFile.write('Final k values:\\n')\n",
    "fitFile.write(str(repr(pars_d[1,:,:].round(decimals=2))) + '\\n')\n",
    "fitFile.write('Final tR values:\\n')\n",
    "fitFile.write(str(repr(pars_d[2,:,:].round(decimals=2))) + '\\n')\n",
    "fitFile.write('Final log-likelihood values:\\n')\n",
    "fitFile.write(str(repr(lls_d.round(decimals=2))) + '\\n')\n",
    "\n",
    "fitFile.write('\\nFinal PC values:\\n')\n",
    "for si in range(nSub):\n",
    "    pcFit_d = np.zeros((nC, nD))\n",
    "    \n",
    "    for ci in range(nC):\n",
    "        pcFit_d[ci,:] = 1 / (1 + np.exp(-2 * pars_d[0,ci,si] * pars_d[1,ci,si] * abs(x_dist[bestx_dist_c[:,si]])))\n",
    "        \n",
    "    fitFile.write(subs[si] + ':\\n')\n",
    "    fitFile.write(str(repr(pcFit_d.round(decimals=2))) + '\\n')\n",
    "    \n",
    "fitFile.write('\\nFinal RT values:\\n')\n",
    "for si in range(nSub):\n",
    "    rtFit_d = np.zeros((nC, nD))\n",
    "    \n",
    "    for ci in range(nC):\n",
    "        rtFit_d[ci,:] = pars_d[0,ci,si] / (pars_d[1,ci,si] * x_dist[bestx_dist_c[:,si]]) * \\\n",
    "                        np.tanh(pars_d[0,ci,si] * pars_d[1,ci,si] * x_dist[bestx_dist_c[:,si]]) + \\\n",
    "                        pars_d[2,ci,si]\n",
    "\n",
    "    fitFile.write(subs[si] + ':\\n')\n",
    "    fitFile.write(str(repr(rtFit_d.round(decimals=2))) + '\\n')\n",
    "    \n",
    "fitFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot average curves\n",
    "\n",
    "# Load average behavior\n",
    "csvFile = '../Data/Behavior/All_behavData.csv'\n",
    "behavData = pd.read_csv(csvFile, header=None)\n",
    "    \n",
    "# Split the file in PC, mean RT and SD RT\n",
    "# Flatten each subject's values for ease of programming\n",
    "temp = np.array(behavData[0:4])\n",
    "pCs = temp[:,[0,1,2]]\n",
    "temp = np.array(behavData[4:8])\n",
    "mRTs = temp[:,[0,1,2]]\n",
    "temp = np.array(behavData[8:12])\n",
    "sdRTs = temp[:,[0,1,2]]\n",
    "    \n",
    "# Get mean and SD values for fits of coherence model\n",
    "pcm_coh = np.mean(pcFit_c, axis=2)\n",
    "pcsd_coh = np.std(pcFit_c, axis=2)\n",
    "\n",
    "rtm_coh = np.mean(rtFit_c, axis=2)\n",
    "rtsd_coh = np.std(rtFit_c, axis=2)\n",
    "\n",
    "# Get mean and SD values for fits of distance model\n",
    "pcm_dist = np.mean(pcFit_d, axis=2)\n",
    "pcsd_dist = np.std(pcFit_d, axis=2)\n",
    "\n",
    "rtm_dist = np.mean(rtFit_d, axis=2)\n",
    "rtsd_dist = np.std(rtFit_d, axis=2)\n",
    "\n",
    "# Plot the figures\n",
    "ymin = 0.3\n",
    "ymax = 1.1\n",
    "plt.figure()\n",
    "plt.subplot(231)\n",
    "plt.plot(pCs,'o-')\n",
    "plt.ylim((ymin,ymax))\n",
    "plt.subplot(232)\n",
    "plt.plot(pcm_coh,'o-')\n",
    "plt.ylim((ymin,ymax))\n",
    "plt.subplot(233)\n",
    "plt.plot(pcm_dist,'o-')\n",
    "plt.ylim((ymin,ymax))\n",
    "\n",
    "ymin = 0.6\n",
    "ymax = 3\n",
    "plt.subplot(234)\n",
    "plt.plot(mRTs,'o-')\n",
    "plt.ylim((ymin,ymax))\n",
    "plt.subplot(235)\n",
    "plt.plot(rtm_coh,'o-')\n",
    "plt.ylim((ymin,ymax))\n",
    "plt.subplot(236)\n",
    "plt.plot(rtm_dist,'o-')\n",
    "plt.ylim((ymin,ymax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pcm_coh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rtm_coh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pcm_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rtm_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
