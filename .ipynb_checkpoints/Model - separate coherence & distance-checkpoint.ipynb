{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In this version of the model, I was trying to model both k and x separately for coherence and distance. \n",
    "# Haven't figured out all the implementation details yet - got pulled in a different direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from math import factorial as fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List subjects to fit\n",
    "subs = ['Sub01', 'Sub02', 'Sub04', 'Sub05', 'Sub06', 'Sub08', 'Sub10', 'Sub11', 'Sub13']\n",
    "nSub = len(subs)\n",
    "\n",
    "# Initialize arrays to hold PC, mean and SD of RT, and # trials \n",
    "# for each coherence-distanct combination\n",
    "# These values are obtained from the .csv files\n",
    "pCs = np.zeros((20, nSub))\n",
    "mRTs = np.zeros((20, nSub))\n",
    "sdRTs = np.zeros((20, nSub))\n",
    "Ns = np.zeros((20, nSub))\n",
    "\n",
    "# Initialise a variable to hold # correct trials\n",
    "# This will be computed from Ns and pCs\n",
    "Rs = np.zeros((20, nSub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract behavioral data (PC, mean and SD of RT, # trials) from csv files\n",
    "for si in range(nSub):\n",
    "    csvFile = '../Data/Behavior/' + subs[si] + '_behavData.csv'\n",
    "    behavData = pd.read_csv(csvFile, header=None)\n",
    "    \n",
    "    # Split the file in PC, mean RT and SD RT\n",
    "    # Flatten each subject's values for ease of programming\n",
    "    pCs[:,si] = np.array(behavData[0:4]).flatten()\n",
    "    mRTs[:,si] = np.array(behavData[4:8]).flatten()\n",
    "    sdRTs[:,si] = np.array(behavData[8:12]).flatten()\n",
    "    Ns[:,si] = np.array(behavData[12:]).flatten()\n",
    "    Rs[:,si] = np.round(Ns[:,si] * pCs[:,si])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters to fit:\n",
    "# A: Boundary\n",
    "# xc, xd: Stimulus strength for coherence, distance\n",
    "# kc, kd: Proportionality constant (Stim. str. = kx)\n",
    "# tR: Residual time\n",
    "\n",
    "# Equations to fit for each stimulus strength:\n",
    "# pC = 1 / (1+exp(-2*A*(kc*abs(xc) + kd*abx(xd)))\n",
    "# mRT = A / (kc*xc + kd*xd) * tanh(A*(kc*xc + kd*xd)) + tR\n",
    "\n",
    "# We can get approximate values for A, k and tR from Palmer et. al. '05\n",
    "# Ranges of parameters to start with:\n",
    "# A: 0.5 - 1\n",
    "# k: 5 - 40\n",
    "# tR: 0.25 - 0.5 (in seconds)\n",
    "# x: 0 - 1\n",
    "\n",
    "# To identify best fit, calculate the likelihood of predicted pC and mRT and find the maximum likelihood.\n",
    "\n",
    "# Likelihood of pC follows a binomial distribution\n",
    "# Lp = n! / (r!(n-r)! * pC(x)^r * (1-pC(x))^(n-r), where\n",
    "# n = # trials, r = # required correct\n",
    "\n",
    "# Likelihood of mRT follows a Gaussian distribution\n",
    "# Lrt = 1 / (SDrt * (sqrt(2*pi))) * e^-((mRT(x) - oRT(x)) / SDrt)^2 * 1/2, where\n",
    "# oRT = observed mRT, mRT = predicted mRT, SDrt = SD of predicted mRT\n",
    "# VARrt = VARtd + VARtr, where\n",
    "# VARtd = variance in decision time, VARtr = variance in residual time. Thus,\n",
    "# VARrt = (A * tanh(A*(kc*xc + kd*xd)) - A*(kc*xc + kd*xd) * sech(A*(kc*xc + kd*xd))) / (kc*xc + kd*xd)^3 + (0.1 * tR)^2\n",
    "\n",
    "# Final fit measure is the log likelihood, which is the sum of the likelihoods of accuracy and mean RT, \n",
    "# over all combinations of coherence and distance\n",
    "# Lprt = sigma(x)(ln(Lp(s)) + ln(Lrt(x)))\n",
    "\n",
    "# The first pass of the model will be to estimate values of x without any assumptions about stimulus relationtips.\n",
    "# The stopping point will be the point of least error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-3dbdb05b8d9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# Initialize arrays that hold predicted accuracies and RTs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mepc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnPar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[0mert\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnPar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0msdrt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnPar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize A, k and tR parameters\n",
    "A, dA = np.linspace(0.5, 5, 10, retstep=True)\n",
    "# k, dk = np.linspace(0.3, 2, 20, retstep=True)\n",
    "kc, dkc = np.linspace(1, 10, 10, retstep=True)\n",
    "kd, dkd = np.linspace(1, 10, 10, retstep=True)\n",
    "tR, dtR = np.linspace(0.2, 1.5, 10, retstep=True)\n",
    "\n",
    "As, kcs, kds, tRs = np.meshgrid(A, kc, kd, tR)\n",
    "As = As.flatten()\n",
    "kcs = kcs.flatten()\n",
    "kds = kds.flatten()\n",
    "tRs = tRs.flatten()\n",
    "\n",
    "# This is the overall number of permutations of A, k and tR being performed\n",
    "nPar = len(As)\n",
    "\n",
    "# Initialize stimulus strength parameter\n",
    "# x, dx = np.linspace(0.1, 10, 200, retstep=True)\n",
    "xc, dxc = np.linspace(0.01, 1, 20, retstep=True)\n",
    "xd, dxd = np.linspace(0.01, 1, 20, retstep=True)\n",
    "\n",
    "xcs, xds = np.meshgrid(xc, xd)\n",
    "xcs = xcs.flatten()\n",
    "xds = xds.flatten()\n",
    "\n",
    "# Initialize arrays that hold predicted accuracies and RTs\n",
    "epc = np.ones((nPar, len(xcs), 20, 9)) * -9\n",
    "ert = np.ones((nPar, len(xcs), 20, 9)) * -9\n",
    "sdrt = np.ones((nPar, len(xcs), 20, 9)) * -9\n",
    "\n",
    "## Initialize the array that holds the\n",
    "# individual likelihood values\n",
    "lpc = np.zeros((nPar, len(xcs), 20, 9))\n",
    "lrt = np.zeros((nPar, len(xcs), 20, 9))\n",
    "# final likelihood values\n",
    "ll = np.ones((nPar, len(xcs), 9)) * -9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From the set of parameters, calculate the (expected) predicted PC and RT\n",
    "# and then find the likelihood that these estimates match the observed PC and RT\n",
    "for si in range(nSub):\n",
    "    for pi in xrange(nPar):\n",
    "        for cdi in range(20):\n",
    "            # Calculate expected accuracy for each coherence-distance combination\n",
    "            epc[pi,:,cdi,si] = 1 / (1 + np.exp(-2 * As[pi] * (kcs[pi]*abs(xc) + kds[pi]*abs(xd))))\n",
    "            # And the likelihood of this accuracy\n",
    "            lpc[pi,:,cdi,si] = fact(Ns[cdi,si]) / (fact(Rs[cdi,si]) * fact(Ns[cdi,si]-Rs[cdi,si])) * \\\n",
    "                                (epc[pi,:,cdi,si] ** Rs[cdi,si]) * \\\n",
    "                                ((1 - epc[pi,:,cdi,si]) ** (Ns[cdi,si] - Rs[cdi,si]))\n",
    "            \n",
    "            # Calculate expected mean RT for each coherence-distance combination\n",
    "            ert[pi,:,cdi,si] = As[pi] / (kcs[pi]*xc + kds[pi]*xd) * np.tanh(As[pi] * (kcs[pi]*xc + kds[pi]*xd)) + tRs[pi] \n",
    "            # And standard error of the mean\n",
    "            sdrt[pi,:,cdi,si] = np.sqrt(((As[pi] * np.tanh(As[pi] * (kcs[pi]*xc + kds[pi]*xd)) - \\\n",
    "                    As[pi] * (kcs[pi]*xc + kds[pi]*xd) * (1/np.cosh(np.square(As[pi] * (kcs[pi]*xc + kds[pi]*xd))))) / \\\n",
    "                    (kcs[pi]*xc + kds[pi]*xd) ** 3 + np.square(0.1 * tRs[pi])) / Ns[cdi,si])\n",
    "            # And the likelihood of observing that RT\n",
    "            lrt[pi,:,cdi,si] = 1 / (sdrt[pi,:,cdi,si] * np.sqrt(2 * np.pi)) * \\\n",
    "                                np.e ** (-1/2 * np.square((ert[pi,:,cdi,si] - mRTs[cdi,si]) / sdrt[pi,:,cdi,si]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# See if there are any weird PC, mRT or sdrt values generated in the parameter space\n",
    "print(np.sum(np.isinf(epc)))\n",
    "print(np.sum(np.isnan(epc)))\n",
    "print(np.sum(epc < 0))\n",
    "print(np.sum(np.isinf(ert)))\n",
    "print(np.sum(np.isnan(ert)))\n",
    "print(np.sum(ert < 0))\n",
    "print(np.sum(np.isinf(sdrt)))\n",
    "print(np.sum(np.isnan(sdrt)))\n",
    "print(np.sum(sdrt < 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find indices where sdrt is NaN (or, variance is negative)\n",
    "tmpId = np.where(np.isnan(sdrt))[0]\n",
    "sdIdx = np.unravel_index(tmpId, sdrt.shape)\n",
    "\n",
    "# Find the fraction of trials that have NaN sdrt - 0.0134\n",
    "print(len(sdIdx[0])/np.double(np.prod(sdrt.shape)))\n",
    "\n",
    "# First see if it's any specific subjects that show this effect - no\n",
    "print(np.unique(sdIdx[3]))\n",
    "for i in range(nSub):\n",
    "    print(np.sum(sdIdx[3] == i))\n",
    "\n",
    "# Any specific CD combinations - no\n",
    "print(np.unique(sdIdx[2]))\n",
    "for i in range(20):\n",
    "    print(np.sum(sdIdx[2] == i))\n",
    "\n",
    "# Any specific x's - smaller ones\n",
    "print(np.unique(sdIdx[1]))\n",
    "for i in range(len(x)):\n",
    "    print(np.sum(sdIdx[1] == i))\n",
    "\n",
    "# Any specific A-k-tR combinations - first one\n",
    "print(np.unique(sdIdx[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bestXcd = np.ones((nPar, 20, nSub)) * -9\n",
    "totLL = np.zeros((nPar, nSub))\n",
    "for si in range(nSub):\n",
    "    for pi in range(nPar):\n",
    "        # At each A-k-tR combination, find the index of x value \n",
    "        # that maximizes likelihood for each CD combination\n",
    "        bestXcd[pi,:,si] = np.argmax(lpc[pi,:,:,si] * lrt[pi,:,:,si],0)\n",
    "        for cdi in range(20):\n",
    "            # Sum over all CDs to obtain overall likelihood for the \n",
    "            # give A-k-tR combination\n",
    "            totLL[pi,si] += np.log(lpc[pi,bestXcd[pi,cdi,si],cdi,si]) + \\\n",
    "                                np.log(lrt[pi,bestXcd[pi,cdi,si],cdi,si])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for si in range(nSub):\n",
    "    plt.subplot(3,3,si+1)\n",
    "    plt.plot(totLL[:,si],'.')\n",
    "    plt.ylim(-200, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the parameters for which likelihood is maximum\n",
    "# There are some NaN values in the likelihood matrix so exclude those\n",
    "maxParId = np.zeros(nSub)\n",
    "\n",
    "# Record the values of best fit x for each CD combination\n",
    "bestx = np.zeros((20, nSub))\n",
    "\n",
    "for si in range(nSub):\n",
    "    maxParId[si] = np.where(totLL[:,si] == np.nanmax(totLL[:,si]))[0]\n",
    "    bestx[:,si] = bestXcd[maxParId[si],:,si]\n",
    "    # print(np.where(maxLLx[:,si] == np.nanmax(maxLLx[:,si]))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for si in range(nSub):\n",
    "    print(totLL[maxParId[si],si])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print the parameter values predicting maximum likelihoods\n",
    "# for the different coherence-distance combinations\n",
    "for si in range(nSub):\n",
    "    print(round(As[maxParId[si]],ndigits=3), round(ks[maxParId[si]],ndigits=3), round(tRs[maxParId[si]],ndigits=3))\n",
    "    print(np.reshape(bestXcd[maxParId[si],:,si],(4,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for si in range(nSub):\n",
    "    temp = []\n",
    "    plt.figure()\n",
    "    plt.subplot(221)\n",
    "    plt.title(subs[si])\n",
    "    plt.plot(np.reshape(pCs[...,si],(4,5)))\n",
    "    ymin, ymax = plt.ylim()\n",
    "    plt.subplot(222)\n",
    "    for cdi in range(20):\n",
    "        temp.append(epc[maxParId[si], bestx[cdi,si], cdi, si])\n",
    "    plt.plot(np.reshape(temp,(4,5)))\n",
    "    plt.ylim((ymin,ymax))\n",
    "\n",
    "    temp = []\n",
    "    plt.subplot(223)\n",
    "    plt.plot(np.reshape(mRTs[...,si],(4,5)))\n",
    "    ymin, ymax = plt.ylim()\n",
    "    plt.subplot(224)\n",
    "    for cdi in range(20):\n",
    "        temp.append(ert[maxParId[si], bestx[cdi,si], cdi, si])\n",
    "    plt.plot(np.reshape(temp,(4,5)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
